[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing Cities and Environment",
    "section": "",
    "text": "Hello! Welcome to my learning diary for CASA0023 Remote Sensing Cities and Environments at the Centre for Advance Spatial Analysis, UCL London.\nI am a socio-cultural geographer, a producer in the culture sector and a spatial data scientist (!) . I got my undergraduate degree at the London School of Economics in Human Geography where I studied topics from urban planning, economic geography, and international development to investigating urban socio-spatial dynamics and role of the creative sector in urban space.\n\nSwiftly after graduation I entered the cultural sector where I assist in theatre, dance, visual art and moving images programme curation and production in Hong Kong and London for three years.\nCurrently at CASA, I would like to further my geographic knowledge and gain technical skills and enter the field of urban sustainability. I am particularly interested in the topics of public housing, equity and climate resilience !\n\n\nThis learning diary is the assignment output of CASA00023 Remote Sensing Cities and Environment. The structure this book will be broken down by weeks, each with a different learning objective.\nThis book is created from R markdown and executable code."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "The electromagnetic spectrum is made up of thousands of bands. From visible light, UV, Infrared, Radar, FM TV, short wave.\n\n\n\n\n\n\n\n\n\n\nThe earth surface either absorb energy or transmit energy.\nThe colour we see is the visible light waves that is reflected off of the object. Apple is red because it absorbs all visible light and reflects red.\n\n\n\n\nSpatial: Size of raster grid per pixel (cm/m). The smaller the measure the more detailed the image will be.\nSpectral: Number of bands from the electromagnetic spectrum it is surveying. Often earth surfaces require multispectral data for it to form a true colour image.\n\nie: green vegetation mainly requires red and near-infrared bands to detect, whereas soil requires mid-infrared bands (6 and 7) to be detected. Bodies of water can be detected mostly within visible light, RBGs.\nLandsat data surveys visible light, near infrared and short wave infrared.\n\nAn example from the practical: This scatter image was produced from sentinel data of Dhakar, Bangladesh. Band 4 = Red Band 8 = NIR * High NIR and Low Red - high vegetation since veg peaks in NIR (see above) * Low red Low NIR - Wet soil.\n\n\n\n\n\n\n\n\n\nTemporal: How frequently the data is collected. Often there is a direct trade off between pixel resolution and update frequency – higher the resolution, lower the update frequency. Good rm data is spenny!!\nRadiometric: Able to identify difference in light or reflectance of Earth surface.\n\nThe higher the bit, the higher the depth, the higher the ability to detect texture\n\nData format: Generally raster, but depending on sensor.\n\nLiDAR is point data in x, y and z (height) → good for elevation models.\n\n\n\n\n\n\n\n\n\n\nA bit of thinking: Applications of varying temporal and spatial resolution, what occasion it’s best for and what satellite provides that spatial resolution. An interesting point is RM data for emergency responses require fairly granular spatial resolution and frequent temporal resolution – so as to track minute changes in landscapes. However as mentioned above, there are direct trade offs between temporal and pixel resolution. For satellites to provide both high temporal and spatial resolution requires huge sums of cost and investment. With growing threats from the climate crisis on the urban landscape – do we currently have the capacity to effectively monitor damages and respond on time?\n\n\n\nRayleigh Scattering: Scattering of waves off of molecules in the air (the atmosphere).\n\nBlue waves are smaller, making it easier to scatter → sky = blue.\nHigher the scatter/absorption, deeper the colour. Deep ocean is dark because there are more water molecules to scatter and absorb waves → no reflection.\n\nBidirectional Reflectance Distribution Function (BRDF):\n\nchanging angles of sensors and levels of illumination\nearth surface that is smooth/diffuse that causes reflectance to go in different directions.\nShadows: Backscattering - sun behind observer | forward scattering - sun opposite observer.\n\nPolarization (SAR data):\n\nEMR waves with 2 waves oscillating perpendicularly. How they reflect depends on texture of the earth surface, moisture, salinity, density, orientation.\nSingle: same polarization transmitted and received\nDual: transmit one, get another\nQuad: transmit and receive up to 4 types.\n\n\n\n\nData Source: Sentinel Data: Copernicus Open Access Hub Landsat Data: Earth Explorer USGS Boundary Data (for masking): https://gadm.org/\nColour compositions: True Colour: colours we see with our eyes B2, B3, B4. False Colour: composite of waves human eyes cannot see. * Infrared: B8, B4, B3. Plants reflect NIR and green light and absorbing red. * Agriculture: B11, B8, B2. Detecting healthy vegetation in dark green * Moisture:(B8A-B11)/(B8A+B11). Detecting water stressed."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction",
    "section": "1.2 Application",
    "text": "1.2 Application\nSince the emergence of accessible Landsat Satellite images in 1967, earth data have since been used for a wide range of purposes including tracking land use, urbanisation, drought, wildfires, biomass changes and other natural and human caused changes (USGS, nd).\n\n1.2.0.1 Environment\nThe Intergovernmental Panel on Climate Change stated Earth observing satellites as a critical and valuable tool to track changes and improving climate predictions (European Space Agency, 2021). Coupled with substantial environmental changes in recent decades, remote sensing data has allowed changes to be tracked and analysed over the last century. Sultana & Satyanarayana (2020) have used satellite imagery to assess the rate of urbanization and urban heat island intensities in urban India. Matricardi et al (2010) analysed the effects of tropical forest degradation as a result of logging and fire, and implemented policy recommendation accordingly, taking advantage of the extensive spectral bands available. Extensive reports by international climate driven bodies have used earth data to measure glacier and sea ice decline, sea level rise and climate modelling.\n\n\n1.2.0.2 Urban Development\nDevelopment of urban areas can be measured with medium to high spatial resolution satellite images including SPOT, Landsat, and Aster, providing a large mass of data on urban growth (Patino, Duque, 2013). Sutton (2013) measured the sprawl of cities using nightime satellite imagery, using lights as a proxy for urban activities. Elkhrachy (2022) has specifically used SAR data to detect depth of flash flood water in risk zones. Kumar & Jain (2017) used earth data and Analytic Hierarchy Process technique to evaluate site suitability for urban development. They specifically looked for geomorphology, transport network, land use/cover and access to ground water. 1 meter spatial resolution images from from IKONOS data was used.\n\n\n\n\n\n\n\n\n\n\n\n1.2.0.3 Assisting social analysis\nSatellite imagery has allowed for a spatial perspective when it comes to studying social processes such as urban poverty, quality of life (Weber & Hirsch 1992), residential desirability (Green 1957). Generating estimation about the urban population was reported to be one of the top 5 recurrent research theme within remote sensing urban environments in 2002 (Phinn, Stanford, Scarth, Murray, & Shyy). For example, Li and Weng (2007) derived environmental variables such as greenness, temperature from Landsat EMT+ as proxies to material and environmental welfare and crowdedness. This is integrated with US census data to generate a Quality of Life Index. Duque, Patino et al (2015) used Quickbird images of 0.6m spatial resolution (extremely high res!!) to generate a intra-urban Slum index. This was executed through per-pixel classification of urban texture and structures."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nRemote sensing data has in a way revolutionised how people approach spatial analysis. Especially since these earth data became publicly available and free to access.\nUtilising the varying spectral properties of earth surfaces and objects, analysis of urban areas have hugely benefitted, with high density buildings, transport networks, urban vegetation — RM data essentially the need to physically surface overviews of urban characteristics (although detailed, high resolution ones still relies on manual surveying).\nAlthough powerful, earth data often needs to be in company of other data, especially demographic, social and economic data for urban analysis to translate into urban policies.\nThere is a wide range of analysis that could be done with RM data, including regression analysis, neural network deep learning, principal component analysis and classification. Options are endless!!!!"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Portfolio Tools",
    "section": "",
    "text": "This week’s learning diary is to produce a Xarigan presentation and host it on a Quarto website. The content of the presentation includes 9 slides on Landsat 8 and 9, providing overview of the satellites (Summary), notable academic papers that have utilised data from these satellites (Application) and individual reflection."
  },
  {
    "objectID": "week3.html#data-correction",
    "href": "week3.html#data-correction",
    "title": "3  Corrections",
    "section": "3.2 Data Correction",
    "text": "3.2 Data Correction\nSatellite data isn’t perfect, will have flaws and we need to fix it before we get into it, yuh.\n\n3.2.1 Geometric Correction\nProcess of removing geometric distortions caused by factors such as sensor perspective (off nadir), terrain relief (hill v flat ground), Wind (on plane) and Earth’s curvature and rotation.\n\n\n\n\n\n\n\n\n\n\n\n3.2.1.1 Solution\nGround Control Points (GPS) to match satellite images to a reference datasets — another map, GPS data etc, using regression.\n\nForward Mapping: we have the xy in a correct image, xiyi in the uncorrected data, and change the data to it.\n\nbut the point is randomly placed on the correct image — not ideal\n\nBackward Mapping: predicting the wrong image with the correct image — more accurate, QGIS.\n\ntakes every point of the correct image and maps it onto the uncorrected image\n\n\nRMSE and Resampling\nNormally RMSE is set as 0.5, but you might want to add more GCPs to reduce RMSE.\nDuring this, data might be slightly shifted → so must resample the final raster by aligning via the nearest neighbour, linear, cubic. But grid cells might not align due to resolution etc etc.\n\n\n\n3.2.2 Atmospheric Correction\n\n3.2.2.1 Mainly scattering & topographic attenuation\nAdjacency Effect: reflective surfaces bleeds into other pixels caused by scattering, making the image hazy and reduces contrast.\n\n\n\nAtmospheric correction for 3 images.\n\n\nWhen and when not to correct:\n\n\n\n\n\n\n\nUnnecessary\nNecessary\n\n\n\n\nClassification of a single image\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\n\n\nIndependent classification of multi date imagery\nUsing spectral signatures through time and space\n\n\nSingle dates data\n\n\n\nAlready Composited images\n\n\n\n\nBUT : Andy corrects it all anyway, just in case\n\n\n3.2.2.2 Solution\nRelative Correction\nTake a really dark pixel ( often the ocean) so that it can be assumed that it does not reflect the atmosphere at all, and subtract it to each pixel as a baseline.\nPsuedo Invariant Features (PIF)\n\nfrom different images to identify features that don’t change (carparks)\ntake regression, where y is the base image, apply model.\nbase model often is the middle one in time series.\n\nAbsolute Correction\n\nChange digital brightness values into a scaled surface reflectance via atmospheric radiative transfer models. This is done to the whole image\nBut this is difficult to do bc needs a lot of data and money.\n\nEmpirical Line Correction\n\nGo out to the field at take measurements using a field spectrometer, but you need to be at the right time a place where the satellite is right above…\nThis is also essentially done through linear regression\n\n\n\n\n3.2.3 Orthorectification Correction\n(Refer to glossary for terms)\nMake things nadir. This would be used if satellite passes adjacent to a mountain top instead of directly above it.\n\n\n\nOrthorectification of a mountain top to nadir.\n\n\nOften uses cosine correction to calculate sun’s zenith and incidence angle\n\n\n3.2.4 Radiometric Calibration\nSatellites capture image brightness and is stored as Digital Number, which has no units and difficult to use!\nRadiometric Calibration is converting DN to spectral radiance.\nAfter all of that…\nThere is Landsat ARD - surface reflectance that is already corrected…\nBut it’s good to know anyway and not all data are ARD (drone images, v high resolution images)"
  },
  {
    "objectID": "week3.html#data-joining",
    "href": "week3.html#data-joining",
    "title": "3  Corrections",
    "section": "3.3 Data Joining",
    "text": "3.3 Data Joining\n\n3.3.1 Mosaicking\nSays what it does on the can! Just like feathering and merging, we are joining 2 or more images together.\nThe images must have some overlapping, or else there’ll be gaps in your map. The overlapping will be dealt with through feathering (blending) so that seamlines are not visible.\nMerging code:\n\nm1 <- terra::mosaic(listlandsat_9i, listlandsat_9ii, fun=\"mean\")"
  },
  {
    "objectID": "week3.html#image-enhancement",
    "href": "week3.html#image-enhancement",
    "title": "3  Corrections",
    "section": "3.4 Image Enhancement",
    "text": "3.4 Image Enhancement\nTo emphasize/exaggerate certain spectral traits. ### Contrast Enhancement\nDifferent materials don’t reflect varying energy back — making it hard to differentiate between things. Images are also designed to avoid saturation in DN.\n\nImage stretching applied to DN\n\n\n3.4.1 Ratio\nDifference between 2 spectral bands that have a certain spectral response – making it easier to identify certain landscape features. This is the NDVI Index, index that refers to a specific item, and uses simple formula to get them.\nRefer to Index Database/ for more!!\nHere we’re extracting healthy vegetation Band 5 - Band 4 (red)\n\nm1_NDVI <- (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 - m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4 ) / (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 + m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4)\n\nm1_NDVI %>%\n  plot(.)\n\n\n\n\n\n\n\n\n\n\nThe greener, there more healthy vegetation there is. Since this is EO image of Dhaka (aka flood zone), vegetation is only present further to the north.\nThis is to filter out features that has higher NDVI score.\n\nveg <- m1_NDVI %>%\n  terra::classify(., cbind(-Inf, 0.2, NA))\n\n\n\n3.4.2 Filtering\nFiltering refers to any kind of moving window operation (zooming out) to our data, saved as a separate raster file, either low or high pass filters.\n\n\n3.4.3 Texture\nUse glcm package to select 8 texture measures.\n\nCan specify size of moving window here\nspecify shift in co-occurency — if there are multiple shifts — will return mean for each pixel.\n\nThis will take 7-10mins!!\n\nglcm <- glcm(band4_raster,\n                   window = c(7, 7),\n                   #shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n                   statistics = c(\"homogeneity\"))\n\nINSERT CODE\n\n\n3.4.4 Data Fusion\nappend new raster data onto existing data OR merge several bands and make new easter dataset\nHere: merging the texture measure (glcm) and the original raster\n\n# for the next step of PCA we need to keep this in a raster (and not terra) format...\nm1_raster <- stack(m1)\n\nFuse <- stack(m1_raster, glcm)\n\n\n\n3.4.5 PCA\nreduce dimensionality of data!\nTo scale data, aka compare data that isnt measured in the same way (spectral bands 4 and 5) and textural data - use the scale function to standardise deviation.\nTo get the mean: use scale = FALSE We can also set the number of samples for PCA\n\nlibrary(RStoolbox)\n\nFuse_3_bands <- stack(Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4, Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5, Fuse$glcm_homogeneity)\n\nscale_fuse<-scale(Fuse_3_bands)\n\npca <- rasterPCA(Fuse, \n                 nSamples =100,\n                 spca = TRUE)\n\n\n\n\n\n\n\n\n\n\nHere Comp 1 & 2 explains 0.81% of the variance. Often this is enough for analysis, so we extract only these 2.\n\n\n\n\n\n\n\n\n\nThis is the output of just layer 1."
  },
  {
    "objectID": "week3.html#a-little-about-data-format",
    "href": "week3.html#a-little-about-data-format",
    "title": "3  Corrections",
    "section": "3.5 A little about data format",
    "text": "3.5 A little about data format\nLandsat data are collected in rows and paths made up of grids of images.\nData is are in tiers and levels.\nTier: Tier 1 denotes best quality, Tier 2 are good but with some clouds that affects radiometric calibration, covering GCPs.\nLevel: Level 1 is delivered through DN, Level 2 has surface reflectance and surface temperature, Level 3 are specific products ie Burned Area, surface water extent."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Corrections",
    "section": "3.6 Application",
    "text": "3.6 Application"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.7 Reflection",
    "text": "3.7 Reflection"
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "Sustainable Development Goals\nUN SDG11: Make cities and human settlements inclusive, safe, resilient and sustainable\nTarget 11.1: By 2030, ensure access for all to adequate, safe and affordable housing and basic services and upgrade slums.\nNairobi Climate Action Plan 2020-2050\n\nUntil the Covid-19 pandemic, Nairobi was one of the fastest growing economies in Africa with annual average growth of 5.9% between 2010 - 2018 (USAid, nd), GDP worth $36 billion (C40, nd)\n2/3 of Kenyans continues to live in poverty, making less than £3.2 per day\n70% Kenyan families are chronically vulnerable to food and nutrition insecurity and preventable diseases.\n75% of Nairobi is informal settlements, with predicted number of urban population living in slums to double in the next 15 years.\nInformal settlements only cover 5% of total residential land of the city. (UN Habitat, 2005)\nThis city is extremely vulnerable against impact of the climate crisis— haltering food security, reduce access to clean water, exposure to extreme heat.\nNairobi has set out 15 climate resilience action to strength the city against extreme weather, of which pertained very little detail onto how laid actions would be implemented.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion on ******how****** the city of Nairobi aims to move towards such goals is unclear from this document.\nThe only mention of geospatial technology (GIS, satellite imagery) is briefly mentioned once, where the government acknowledge the lack of GIS technology to further enable an accessible and wide-spread urban transit system.\nThis shows the Nairobi government has a little idea onto how to harness Earth Observation data to push forward their urban climate agenda.\nBuild houses in climate sensitive areas?????\nSlum mapping — see where slums will expand and provide amenities accordingly."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIncrease access to climate resilience programme — Identify arid land/flood zones, disaster mapping.\n\nSlum identification — see where slums will expand and provide amenities accordingly.\nhttps://www.mdpi.com/2072-4292/8/6/455"
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection"
  }
]