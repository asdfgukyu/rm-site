[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing Cities and Environment",
    "section": "",
    "text": "Hello! Welcome to my learning diary for CASA0023 Remote Sensing Cities and Environments at the Centre for Advance Spatial Analysis, UCL London.\nI am a socio-cultural geographer, a producer in the culture sector and a spatial data scientist (!) . I got my undergraduate degree at the London School of Economics in Human Geography where I studied topics from urban planning, economic geography, and international development to investigating urban socio-spatial dynamics and role of the creative sector in urban space.\n\nAfter graduation, I entered the cultural sector where I worked in theatre, dance, visual art and moving images programme curation and production in Hong Kong and London for three years.\nAt CASA, I am looking to develop my geographic knowledge, gain technical skills and - hopefully - enter the field of urban sustainability. I am particularly interested in the topics of public housing, social justice and climate resilience !\n\n\nThis learning diary is the assignment output of CASA00023 Remote Sensing Cities and Environment. This book is broken down by weeks, each with a different learning objective.\nThis book is created from R markdown and executable code."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "The electromagnetic spectrum is made up of thousands of bands, including visible light, UV, infrared, radar, FM, TV and short wave.\n\n\n\n\n\n\n\n\n\n\nThe earth’s surface either absorbs energy or transmits energy.\nThe colour we see is the visible light waves that is reflected off of the object. Apple is red because it reflects red and absorbs all other visible light.\n\n\n\n\nSpatial: The size of a raster grid per pixel (cm/m). The smaller the measure, the more detailed the image.\nSpectral: The number of bands from the electromagnetic spectrum being surveyed. Often earth surfaces require multispectral data to form a true colour image.\n\ni.e. green vegetation mostly requires red and near-infrared bands to detect, whereas soil requires mid-infrared bands (6 and 7) to be detected; bodies of water can be detected mostly within visible light (RBGs).\nLandsat data surveys visible light, near infrared and short wave infrared.\n\nAn example from the practical: The below scatter image was produced from sentinel data of Dhakar, Bangladesh. Band 4 = Red Band 8 = NIR * High NIR and Low Red - high vegetation since veg peaks in NIR (see above) * Low red Low NIR - Wet soil.\n\n\n\n\n\n\n\n\n\nTemporal: How frequently the data is collected. Often there is a direct trade-off between pixel resolution and update frequency – the higher the resolution, the lower the update frequency. Good rm data is spenny!!\nRadiometric: Able to identify difference in light or reflectance of Earth surface.\n\nThe higher the bit, the higher the depth, the higher the ability to detect texture.\n\nData format: Generally raster, but depending on sensor.\n\nLiDAR is point data in x, y and z (height) → good for elevation models.\n\n\n\n\n\n\n\n\n\n\nA bit of thinking: Applications of varying temporal and spatial resolution, what occasion it’s best for and what satellite provides that spatial resolution. An interesting point is RM data for emergency responses require fairly granular spatial resolution and frequent temporal resolution – so as to track minute changes in landscapes. However as mentioned above, there are direct trade offs between temporal and pixel resolution. For satellites to provide both high temporal and spatial resolution requires huge sums of cost and investment. With growing threats from the climate crisis on the urban landscape – do we currently have the capacity to effectively monitor damages and respond on time?\n\n\n\nRayleigh Scattering: Scattering of waves off of molecules in the air (the atmosphere).\n\nBlue waves are smaller, making it easier to scatter → sky = blue.\nHigher the scatter/absorption, deeper the colour. Deep ocean is dark because there are more water molecules to scatter and absorb waves → no reflection.\n\nBidirectional Reflectance Distribution Function (BRDF):\n\nchanging angles of sensors and levels of illumination\nearth surface that is smooth/diffuse that causes reflectance to go in different directions.\nShadows: Backscattering - sun behind observer | forward scattering - sun opposite observer.\n\nPolarization (SAR data):\n\nEMR waves with 2 waves oscillating perpendicularly. How they reflect depends on texture of the earth surface, moisture, salinity, density, orientation.\nSingle: same polarization transmitted and received\nDual: transmit one, get another\nQuad: transmit and receive up to 4 types.\n\n\n\n\nData Source: Sentinel Data: Copernicus Open Access Hub Landsat Data: Earth Explorer USGS Boundary Data (for masking): https://gadm.org/\nColour compositions: True Colour: colours we see with our eyes B2, B3, B4. False Colour: composite of waves human eyes cannot see. * Infrared: B8, B4, B3. Plants reflect NIR and green light and absorbing red. * Agriculture: B11, B8, B2. Detecting healthy vegetation in dark green * Moisture:(B8A-B11)/(B8A+B11). Detecting water stressed."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction",
    "section": "1.2 Application",
    "text": "1.2 Application\nSince the emergence of accessible Landsat Satellite images in 1967, earth data has been used for a wide range of purposes including tracking land use, urbanisation, drought, wildfires, biomass changes and other natural and human caused changes (USGS, nd).\n\n1.2.0.1 Environment\nThe Intergovernmental Panel on Climate Change stated earth-observing satellites are a critical and valuable tool to track changes and improving climate predictions (“ESA and Climate” (n.d.)). Coupled with substantial environmental changes in recent decades, remote sensing data has allowed changes to be tracked and analysed over the last century. Sultana and Satyanarayana (2020) have used satellite imagery to assess the rate of urbanisation and urban heat island intensities in urban India. Matricardi et al. (2010) analysed the effects of tropical forest degradation as a result of logging and fire, and implemented policy recommendation accordingly, taking advantage of the extensive spectral bands available. Extensive reports by international climate driven bodies have used earth data to measure glacier and sea ice decline, sea level rise and climate modelling.\n\n\n1.2.0.2 Urban Development\nDevelopment of urban areas can be measured with medium to high spatial resolution satellite images including SPOT, Landsat, and Aster, providing a large mass of data on urban growth (Patino and Duque (2013)). Sutton (2003) measured the sprawl of cities using nighttime satellite imagery, using lights as a proxy for urban activities. Elkhrachy (2022) has specifically used SAR data to detect depth of flash flood water in risk zones. “Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink” (n.d.) used earth data and Analytic Hierarchy Process technique to evaluate site suitability for urban development. They specifically looked for geomorphology, transport network, land use/cover and access to ground water. 1 meter spatial resolution images from from IKONOS data was used.\n\n\n\n\n\n\n\n\n\n\n\n1.2.0.3 Assisting social analysis\nSatellite imagery has allowed for a spatial perspective when it comes to studying social processes such as urban poverty, quality of life (WEBER and HIRSCH (1992)), residential desirability (Green (1957)). Generating estimation about the urban population was reported to be one of the top 5 recurrent research theme within remote sensing urban environments Phinn et al. (2002). For example, Li and Weng (2007) derived environmental variables such as greenness, temperature from Landsat EMT+ as proxies to material and environmental welfare and crowdedness. This is integrated with US census data to generate a Quality of Life Index. Duque et al. (2015) used Quickbird images of 0.6m spatial resolution (extremely high res!!) to generate a intra-urban Slum index. This was executed through per-pixel classification of urban texture and structures."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nRemote sensing data has in a way revolutionised how people approach spatial analysis, providing an unprecedented amount of data about the earth’s surface with lrelatively ow barriers to access compared to previous available methods, such as costal surveying. This has been especially true since remote sensing data became publicly available, democratising access.\nUtilising the varying spectral properties of earth surfaces and objects, our understanding and ability to analyse urban areas has significantly improved, with scientists more easily able to map high density buildings, transport networks and urban vegetation. RM data essentially removes the need to physically surface overviews of urban characteristics (although detailed, high resolution analysis still relies on manual surveying).\nAlthough powerful, earth data is often used in conjunction with other data, especially demographic, social and economic data for urban analysis to translate into urban policies. For example, satellite imaging can be used to map certain visible characteristics of urban poverty, alongside census data to give a more nuanced picture.\nThere is a wide range of analysis that could be done with RM data, including regression analysis, neural network deep learning, principal component analysis and classification. The options are endless!!!!\n\n\n\n\n\nDuque, Juan C., Jorge E. Patino, Luis A. Ruiz, and Josep E. Pardo-Pascual. 2015. “Measuring Intra-Urban Poverty Using Land Cover and Texture Metrics Derived from Remote Sensing Data.” Landscape and Urban Planning 135 (March): 11–21. https://doi.org/10.1016/j.landurbplan.2014.11.009.\n\n\nElkhrachy, Ismail. 2022. “Flash Flood Water Depth Estimation Using SAR Images, Digital Elevation Models, and Machine Learning Algorithms.” Remote Sensing 14 (3): 440. https://doi.org/10.3390/rs14030440.\n\n\n“ESA and Climate.” n.d. https://www.esa.int/Applications/Observing_the_Earth/Space_for_our_climate/ESA_and_climate.\n\n\nGreen, Norman. 1957. “Aerial Photographic Interpretation and the Social Structure of the City.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nLi, G., and Q. Weng. 2007. “Measuring the Quality of Life in City of Indianapolis by Integration of Remote Sensing and Census Data.” International Journal of Remote Sensing 28 (2): 249–67. https://doi.org/10.1080/01431160600735624.\n\n\nMatricardi, Eraldo A. T., David L. Skole, Marcos A. Pedlowski, Walter Chomentowski, and Luis Claudio Fernandes. 2010. “Assessment of Tropical Forest Degradation by Selective Logging and Fire Using Landsat Imagery.” Remote Sensing of Environment 114 (5): 1117–29. https://doi.org/10.1016/j.rse.2010.01.001.\n\n\nPatino, Jorge E., and Juan C. Duque. 2013. “A Review of Regional Science Applications of Satellite Remote Sensing in Urban Settings.” Computers, Environment and Urban Systems 37 (January): 1–17. https://doi.org/10.1016/j.compenvurbsys.2012.06.003.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002. “Monitoring the Composition of Urban Environments Based on the Vegetation-Impervious Surface-Soil (VIS) Model by Subpixel Analysis Techniques.” International Journal of Remote Sensing 23 (20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\n“Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink.” n.d. https://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\nSultana, Sabiha, and A. N. V. Satyanarayana. 2020. “Assessment of Urbanisation and Urban Heat Island Intensities Using Landsat Imageries During 2000 2018 over a Sub-Tropical Indian City.” Sustainable Cities and Society 52 (January): 101846. https://doi.org/10.1016/j.scs.2019.101846.\n\n\nSutton, Paul C. 2003. “A Scale-Adjusted Measure of ‘Urban Sprawl’ Using Nighttime Satellite Imagery.” Remote Sensing of Environment, Urban Remote Sensing, 86 (3): 353–69. https://doi.org/10.1016/S0034-4257(03)00078-6.\n\n\nWEBER, C., and J. HIRSCH. 1992. “Some Urban Measurements from SPOT Data: Urban Life Quality Indices.” International Journal of Remote Sensing 13 (17): 3251–61. https://doi.org/10.1080/01431169208904116."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Portfolio Tools",
    "section": "",
    "text": "This week’s learning diary is to produce a Xarigan presentation and host it on a Quarto website. The content of the presentation includes 9 slides on Landsat 8 and 9, providing overview of the satellites (Summary), notable academic papers that have utilised data from these satellites (Application) and individual reflection."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "This week is about image corrections, including geometric correction, atmospheric correction, relative correction, absolute correction, empirical line correction, orthorectification correction, mosaicking, texturing and PCA.\nCode provided is in R."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary"
  },
  {
    "objectID": "week3.html#data-correction",
    "href": "week3.html#data-correction",
    "title": "3  Corrections",
    "section": "3.2 Data Correction",
    "text": "3.2 Data Correction\nSatellite data isn’t perfect, will have flaws and we need to fix it before we get into it, yuh.\n\n3.2.1 Geometric Correction\nProcess of removing geometric distortions caused by factors such as sensor perspective (off nadir), terrain relief (hill v flat ground), Wind (on plane) and Earth’s curvature and rotation.\n\n\n\n\n\n\n\n\n\n\n\n3.2.1.1 Solution\nGround Control Points (GPS) to match satellite images to a reference datasets — another map, GPS data etc, using regression.\n\nForward Mapping: we have the xy in a correct image, xiyi in the uncorrected data, and change the data to it.\n\nbut the point is randomly placed on the correct image — not ideal\n\nBackward Mapping: predicting the wrong image with the correct image — more accurate, QGIS.\n\ntakes every point of the correct image and maps it onto the uncorrected image\n\n\nRMSE and Resampling\nNormally RMSE is set as 0.5, but you might want to add more GCPs to reduce RMSE.\nDuring this, data might be slightly shifted → so must resample the final raster by aligning via the nearest neighbour, linear, cubic. But grid cells might not align due to resolution etc etc.\n\n\n\n3.2.2 Atmospheric Correction\n\n3.2.2.1 Mainly scattering & topographic attenuation\nAdjacency Effect: reflective surfaces bleeds into other pixels caused by scattering, making the image hazy and reduces contrast.\n\n\n\nAtmospheric correction for 3 images.\n\n\nWhen and when not to correct:\n\n\n\n\n\n\n\nUnnecessary\nNecessary\n\n\n\n\nClassification of a single image\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\n\n\nIndependent classification of multi date imagery\nUsing spectral signatures through time and space\n\n\nSingle dates data\n\n\n\nAlready Composited images\n\n\n\n\nBUT : Andy corrects it all anyway, just in case\n\n\n3.2.2.2 Solution\nRelative Correction\nTake a really dark pixel ( often the ocean) so that it can be assumed that it does not reflect the atmosphere at all, and subtract it to each pixel as a baseline.\nPsuedo Invariant Features (PIF)\n\nfrom different images to identify features that don’t change (carparks)\ntake regression, where y is the base image, apply model.\nbase model often is the middle one in time series.\n\nAbsolute Correction\n\nChange digital brightness values into a scaled surface reflectance via atmospheric radiative transfer models. This is done to the whole image\nBut this is difficult to do bc needs a lot of data and money.\n\nEmpirical Line Correction\n\nGo out to the field at take measurements using a field spectrometer, but you need to be at the right time a place where the satellite is right above…\nThis is also essentially done through linear regression\n\n\n\n\n3.2.3 Orthorectification Correction\n(Refer to glossary for terms)\nMake things nadir. This would be used if satellite passes adjacent to a mountain top instead of directly above it.\n\n\n\nOrthorectification of a mountain top to nadir.\n\n\nOften uses cosine correction to calculate sun’s zenith and incidence angle\n\n\n3.2.4 Radiometric Calibration\nSatellites capture image brightness and is stored as Digital Number, which has no units and difficult to use!\nRadiometric Calibration is converting DN to spectral radiance.\nAfter all of that…\nThere is Landsat ARD - surface reflectance that is already corrected…\nBut it’s good to know anyway and not all data are ARD (drone images, v high resolution images)"
  },
  {
    "objectID": "week3.html#data-joining",
    "href": "week3.html#data-joining",
    "title": "3  Corrections",
    "section": "3.3 Data Joining",
    "text": "3.3 Data Joining\n\n3.3.1 Mosaicking\nSays what it does on the can! Just like feathering and merging, we are joining 2 or more images together.\nThe images must have some overlapping, or else there’ll be gaps in your map. The overlapping will be dealt with through feathering (blending) so that seamlines are not visible.\nMerging code:\n\nm1 <- terra::mosaic(listlandsat_9i, listlandsat_9ii, fun=\"mean\")"
  },
  {
    "objectID": "week3.html#image-enhancement",
    "href": "week3.html#image-enhancement",
    "title": "3  Corrections",
    "section": "3.4 Image Enhancement",
    "text": "3.4 Image Enhancement\nTo emphasize/exaggerate certain spectral traits. ### Contrast Enhancement\nDifferent materials don’t reflect varying energy back — making it hard to differentiate between things. Images are also designed to avoid saturation in DN.\n\nImage stretching applied to DN\n\n\n3.4.1 Ratio\nDifference between 2 spectral bands that have a certain spectral response – making it easier to identify certain landscape features. This is the remote sensing index, index that refers to a specific item, and uses simple formula to get them.\nRefer to Index Database for more!! There is an index for virtually everything on earth. From soil type, tree health, moisture level, rock/metal type etc etc…\nHere we’re extracting healthy vegetation, formula from Normalized Difference Vegetation Index. Band 5 - Band 4 (red)\n\nm1_NDVI <- (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 - m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4 ) / (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 + m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4)\n\nm1_NDVI %>%\n  plot(.)\n\n\n\n\n\n\n\n\n\n\nThe greener, there more healthy vegetation there is. Since this is EO image of Dhaka (aka flood zone), vegetation is only present further to the north.\nThis is to filter out features that has higher NDVI score.\n\nveg <- m1_NDVI %>%\n  terra::classify(., cbind(-Inf, 0.2, NA))\n\n\n\n3.4.2 Filtering\nFiltering refers to any kind of moving window operation (zooming out) to our data, saved as a separate raster file, either low or high pass filters.\n\n\n3.4.3 Texture\nUse glcm package to select 8 texture measures.\n\nCan specify size of moving window here\nspecify shift in co-occurency — if there are multiple shifts — will return mean for each pixel.\n\nThis will take 7-10mins!!\n\nglcm <- glcm(band4_raster,\n                   window = c(7, 7),\n                   #shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n                   statistics = c(\"homogeneity\"))\n\nINSERT CODE\n\n\n3.4.4 Data Fusion\nappend new raster data onto existing data OR merge several bands and make new easter dataset\nHere: merging the texture measure (glcm) and the original raster\n\n# for the next step of PCA we need to keep this in a raster (and not terra) format...\nm1_raster <- stack(m1)\n\nFuse <- stack(m1_raster, glcm)\n\n\n\n3.4.5 PCA\nreduce dimensionality of data!\nTo scale data, aka compare data that isnt measured in the same way (spectral bands 4 and 5) and textural data - use the scale function to standardise deviation.\nTo get the mean: use scale = FALSE We can also set the number of samples for PCA\n\nlibrary(RStoolbox)\n\nFuse_3_bands <- stack(Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4, Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5, Fuse$glcm_homogeneity)\n\nscale_fuse<-scale(Fuse_3_bands)\n\npca <- rasterPCA(Fuse, \n                 nSamples =100,\n                 spca = TRUE)\n\n\n\n\n\n\n\n\n\n\nHere Comp 1 & 2 explains 0.81% of the variance. Often this is enough for analysis, so we extract only these 2.\n\n\n\n\n\n\n\n\n\nThis is the output of just layer 1."
  },
  {
    "objectID": "week3.html#a-little-about-data-format",
    "href": "week3.html#a-little-about-data-format",
    "title": "3  Corrections",
    "section": "3.5 A little about data format",
    "text": "3.5 A little about data format\nLandsat data are collected in rows and paths made up of grids of images.\nData is are in tiers and levels.\nTier: Tier 1 denotes best quality, Tier 2 are good but with some clouds that affects radiometric calibration, covering GCPs.\nLevel: Level 1 is delivered through DN, Level 2 has surface reflectance and surface temperature, Level 3 are specific products ie Burned Area, surface water extent."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Corrections",
    "section": "3.6 Application",
    "text": "3.6 Application\nWe outlined generally how these corrections and enhancements are executed. However when it comes to application, there are lots of debates around how best to correct/enhance an image.\nFor example, Wang et al. (2012) found we choose and design the Ground Control Points (GCPs) have strong effects on the accuracy of geometric correction. They used a universal kriging model-based sampling method that takes into account the spatial auto-covariance of regression residual, and extracts results accordingly. They found that the more disperse and even the distribution of the GCPs, the higher the geometric correction precision.\nAcademics also develop new methods of correction and enhancements specifically to extract earth features they want and accessibility of certain methods. Pandey, Tate, and Balzter (2014) use PCA to map tree species in coastal Portugal depending on the tree species’ reflectance signatures. He highlighted the high cost involved to do this using GCPs, and that the increasing temporal and spectral frequency of earth data made developing automatic image registration software possible. At the end 15 PC layers contained 99.42% of the information of the original hyperspectral image.\nSometimes you don’t know if an image needs to be corrected or not if there are no obvious signs of haze or clouds visible to us. In a similar vein to reduce costly ground observation data (but also to test whether atmospheric correction (AC) is needed for improving the reliability of the estimated values of 2 key clear water parameters), Sriwongsitanon, Surakit, and Thianpopirug (2011) evaluated the influence of atmospheric correction and number of sampling points on the accuracy of water clarity assessment. They collected data on clarity and sediment parameters at 80 ground observation points as reference and used three Landsat 5 TM images to conduct the experiment in the largest lake in Thailand. They found AC has a statistically significant influence over the max and min values of the sediment parameter and clarity parameter, making the images more accurate in assessing water clarity, thus encouraged to be applied to when assessing clarity of water. They also concluded that only 32/80 of the observation points were needed for the satellite image to obtain a reliable assessment as a result of AC, instead of all 80. (wohoo!)"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.7 Reflection",
    "text": "3.7 Reflection\nUnderstanding how satellite images are tweaked and handled before they could actually be used for analysis feels the same as data cleaning before we go into EDA. Although cumbersome at times, I feel this is the most effective way to get to know data before conducting analysis. It’s also generally good practice to understand how values are generated through by calculating them step by step, rather than just one line of code provided by a package. We will eventually encounter data that isn’t corrected. It’s good to at least to know generally how to approach correction. I’m also looking forward to GEE and see how the platform streamlines the process.\nThe possibilities with Earth Observation data seems to be… endless? Essentially anything activities larger than 10 by 10m can be detected on satellite images. That thought in itself is quite overwhelming, because when you can do everything, where do you start?\nIt’s been very useful to know how these correction and enhancement methods work before we dive straight into GEE with ARD. Surprisingly I didn’t find this week’s content that overwhelming (compared to week 7, just you wait). In contrast I really felt it laid the necessary foundation for me to understand how one would process earth observation data. I feel more confident knowing how to deal with earth observation data, in case I ever need to deal with raw images.\n\n\n\n\nPandey, Prem Chandra, Nicholas J. Tate, and Heiko Balzter. 2014. “Mapping Tree Species in Coastal Portugal Using Statistically Segmented Principal Component Analysis and Other Methods.” IEEE Sensors Journal 14 (12): 4434–41. https://doi.org/10.1109/JSEN.2014.2335612.\n\n\nSriwongsitanon, Nutchanart, Kritsanat Surakit, and Sansarith Thianpopirug. 2011. “Influence of Atmospheric Correction and Number of Sampling Points on the Accuracy of Water Clarity Assessment Using Remote Sensing Application.” Journal of Hydrology 401 (3): 203–20. https://doi.org/10.1016/j.jhydrol.2011.02.023.\n\n\nWang, Jianghao, Yong Ge, Gerard B. M. Heuvelink, Chenghu Zhou, and Dick Brus. 2012. “Effect of the Sampling Design of Ground Control Points on the Geometric Correction of Remotely Sensed Imagery.” International Journal of Applied Earth Observation and Geoinformation 18 (August): 91–100. https://doi.org/10.1016/j.jag.2012.01.001."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "This week focuses on how we may utilise insights gained from Earth Observation analysis to assist local, regional and national government to implement data-drive policies, whilst increasing compliance to urban/global agendas."
  },
  {
    "objectID": "week4.html#case-study-informal-settlements-in-nairobi-kenya",
    "href": "week4.html#case-study-informal-settlements-in-nairobi-kenya",
    "title": "4  Policy",
    "section": "4.1 Case Study: Informal Settlements in Nairobi, Kenya",
    "text": "4.1 Case Study: Informal Settlements in Nairobi, Kenya\n\n4.1.1 Context\n\n\n\n\n\nSource: (globalpartnershipforresult-basedappraoachesKenyaAssessmentKayoleSowetond?).\n\n\n\n\n\nUntil the Covid-19 pandemic, Nairobi was one of the fastest growing urban economies in Africa with annual average GDP growth of 5.9% between 2010 - 2018 (“Economic Growth and Trade | Kenya” (Mon, 02/13/2023 - 14:17)). The GDP of the city amounted to 36 billion USD (“Nairobi” (n.d.)).\nDespite rapid economic growth, the city has been unable to provide housing infrastructure for its increasing population. The spoils of growth have not yet been used to support the city’s sustainable expansion.\n75% of urban population growth in Nairobi is accounted for by informal settlements, and the proportion of urban population living in slums is predicted to double in the next 15 years.\nInformal settlements cover 5% of total residential land of the city but house half of the city’s total population (Habitat (n.d.)).\n2/3 of Kenyans continue to live in poverty, making less than 3.2 GBP per day.\n70% Kenyan families are chronically vulnerable to food and nutrition insecurity and preventable diseases.\nNairobi is also extremely vulnerable to impact of the climate crisis – leading to food insecurity, reducing access to clean water, and exposing residents to increasingly frequent instances extreme heat and preventable diseases.\n\n\n\n4.1.2 International Framework\nSustainable Development Goals\n\n\n\n\n\n17 Sustainable Development Goals. Source: (unitednationsCommunicationsMaterialsn.d?).\n\n\n\n\nThe Sustainable Development Goals are a set of 17 objectives that serve as a ‘blueprint to a to achieve a better and more sustainable future for all’, devised and led by the United Nations. The SDGs pushes for sustainable development that recognises the interconnectedness of social, economic and environmental aspect of society.\nRelevant goals:\nUN SDG02: End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\n\nTarget 02.1: By 2030, end hunger and ensure access by all people, in particular the poor and people in vulnerable situations, including infants, to safe, nutritious and sufficient food all year round.\nIndicator: Prevalence of moderate or severe food insecurity in the population, based on the Food Insecurity Experience Scale (FIES).\n\nUN SDG06: Ensure availability and sustainable management of water and sanitation for all.\n\nTarget 06.2: By 2030, achieve access to adequate and equitable sanitation and hygiene for all and end open defecation, paying special attention to the needs of women and girls and those in vulnerable situations.\nIndicator: Proportion of population using (a) safely managed sanitation services and (b) a hand-washing facility with soap and water.\n\nUN SDG11: Make cities and human settlements inclusive, safe, resilient and sustainable.\n\nTarget 11.1: By 2030, ensure access for all to adequate, safe and affordable housing and basic services and upgrade slums.\nIndicator: Proportion of urban population living in slums, informal settlements or inadequate housing.\n\n\n\n4.1.3 Urban-level framework\nNairobi Climate Action Plan 2020-2050\n\nNairobi has set out 15 climate resilience actions to strength the city against extreme weather, of which pertained very little detail onto how laid actions would be implemented.\n\nRelevant actions include: #### Action 13: increase access to a climate resilience programme.\n\n\n\n\n\n\n\n\n\n\nHow the city of Nairobi aims to move towards such goals is unclear from this document.\nGeospatial technology (GIS, satellite imagery) is mentioned only once, where the local authority acknowledges that the lack of GIS technology means that they are unable to provide an accessible and wide-spread urban transit system.\nThis shows the Nairobi government is unable at present to effectively harness Earth Observation data to push forward their urban climate agenda.\nThe document also seems to encourage residential house building in climate sensitive areas.\nSlum mapping — see where slums will expand and provide amenities accordingly."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nInformal settlements in Nairobi are recognised as a serious issues by the city level government and national government, and is referenced by the United Nations as a worsening problem.\nInformal settlements need to be identified easily, at low cost and with increasing frequency, so that the local government is able to understand the direction of their expansion and population variations within the settlements.\nGeospatial mapping would enable local authorities to build much-needed sanitation infrastructure in areas of high and increasing population density. An up-to-date understanding of the growing population in informal settlements could provide much-needed information for social policymakers for wider programmes of healthcare, education or other public services.\nEarth observation data would also allow the government to identify areas of environmental vulnerability so that they are able to concentrate limited resources on regulating or halting the further expansion of informal settlements in the most environmentally sensitive areas.\n\n4.2.1 Slum identification\n\n4.2.1.1 Data\n\n\n4.2.1.2 Methodology\nLeonita et al. (2018) used spport vector machine (SVM) and random forest (RF), for slum mapping in support of the slum mapping campaign in Bandung, Indonesia."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nWithout the necessary public policy interventions or structures in place, rapid economic growth can coexist with increasingly severe housing, environmental and health issues. The right understanding of the urban landscape, how it is changing and what the demographic and economic profile of residents are can be used to solve some of those problems.\nGeospatial data is useful not just to evaluate the existing status of built environments but as a tool to observe almost real-time changes in a rapidly expanding urban environment. This provides signifcant advantages for policymakers who are often required to dedicate limited resources to solving rapidly changing problems, moreso in areas such as Nairobi where there is a fast-growing population and increasingly severe problem of informal settlements.\nEarth observation data is not always widely used in the policy space, and is - particularly in this instance - sometimes not seriously acknowledged by governments as a major tool for urban policymaking, despite its relatively low cost to access and high potential to improve the understanding of the urban landscape. It is unclear why this is the case, and what could be done to draw greater attention to geospatial data within policymaking at a local level.\n\n\n\n\n\n“Economic Growth and Trade | Kenya.” Mon, 02/13/2023 - 14:17. U.S. Agency for International Development. https://www.usaid.gov/kenya/economic-growth-and-trade.\n\n\nHabitat, UN. n.d. “Kenya: Nairobi Urban Profile | UN-Habitat.” UN Habitat. https://unhabitat.org/kenya-nairobi-urban-profile.\n\n\nLeonita, Gina, Monika Kuffer, Richard Sliuzas, and Claudio Persello. 2018. “Machine Learning-Based Slum Mapping in Support of Slum Upgrading Programs: The Case of Bandung City, Indonesia.” Remote Sensing 10 (10): 1522. https://doi.org/10.3390/rs10101522.\n\n\n“Nairobi.” n.d. C40 Cities. https://www.c40.org/cities/nairobi/."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Introduction to Google Earth Engine",
    "section": "",
    "text": "Because this week’s material is mainly to get acquainted with GEE using the skills and methodologies we learnt in previous weeks – this week’s learning diary will mainly feature GEE scripts, so I can refer here for main codes for basic analysis."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nWhat is GEE?\nA geospatial processing service, allow for large scale analysis - EO data are all stored on the server Handy because it maps out the output immediately — good for visualisation\nGoogle does things a little differently…\nNaming Things…\n\n\n\nGee\nR\n\n\n\n\nImage\nRaster\n\n\nFeature\nVector\n\n\nImageCollection\nFeatureCollection (multiple polygons)\n\n\n\nUses Javascript\nCan’t run individual code chunk → must run the whole script!\nClient v Server Side\n\n\n\n\n\n\n\nClient\nServer\n\n\n\n\nFrontend\nBackend\n\n\nOur scripts\nprocessing the code\n\n\nlight! Nothing store locally\nstoring all EO data (anything with .ee in it)\n\n\n\nNotes:\n\nDon’t loop something on the server, looping is computationally very inefficient and loop doesn’t know what’s inside the .ee\nBut a function (ie mapping) is welcomed, so that it can be saved as an object\nMapping: make a function and apply to the entire collection\n\nonly loading the initially colelction once!\n\n\nScale (aka pixel resolution)\nMost things in GEE is aggregated, and GEE will automatically select the closest scale to your analysis and resample it.\nAlways set the scale parameters to what you need, if not, it will default to the zoom level of the map.\nAlways try to put in the scale:scale line\nProjection\nNo need to think about projection, until exporting it out of GEE\nAny new shapefile will be automatically transformed\nGEE converts all their OE data to WGS84 Mercator (EPSG3857). Operations of projections are determined by output — meaning they do the working figuring out what you need, and give it to you.\nObject Class\n\nGeometry: point, line, polygon with no attributes\nFeature: geometry with attribute table, single polygon\n\nThing to manipulate data with\n\nReducer: take loads of data to one thing (zonal statistics)\nJoin: can even join landsat and sentinel data!\nArray: spreadsheet\n\n\n\n\n\n\nObject class. Source: (ObjectsMethodsOverview?)\n\n\n\n\n\n5.1.1 Applying\n\n\n\n\n\nProcess of GEE analysis in Week 5 practical\n\n\n\n\n\n5.1.1.1 Loading In\nWhen loading in ee.ImageCollection , we need to/can specify:\n\n.filterDate(’start date’, ‘end date’)\n.filter(ee.Filter.calendarRange(1, 2, 'month'))\n.filterBounds(PlaceName)\n.filter(ee.Filter.lt(”CLOUD_COVER”, 0.1))\n\nAdd Features & Geometries\nImport GADM boundary map that has Delhi boundaries, in this case column GID_1 row IND.25.1_1\n\nvar india = ee.FeatureCollection('users/asdfgukyu/india-2')\n    .filter('GID_1 == \"IND.25_1\"');\n\nLoad Landsat 9 data\nfilter by date, month, and bound. Each image has 19 bands, and when we add the map layer, with no filter on the bands to include.\n\nvar oneimage = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n  .filterDate('2020-01-01', '2022-10-10')\n  .filterBounds(india)  // Intersecting ROI\n  .filter(ee.Filter.lt(\"CLOUD_COVER\", 0.1));\n\nTrue Layer\nIf we want to get a true colour layer made with RGB.\n\nMap.addLayer(oneimage, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]})\n\nOtherwise, if we want all 19 bands:\n\nMap.addLayer(oneimage)\n\n\n\n\n\n\n\n\n\n\nBoth of the results show very dark images, but no clouds. We need to reduce all of these images so we get 1 that we can work with. We’re going ahead with the 19 bands here (oneimage).\nDeveloping an image reducer The method we used here is reducing by median, but there are better ways to do this, like percentile or seasonal methods.\n\nvar median = oneimage.reduce(ee.Reducer.median());\nprint(median, \"median\") //Print to Console\n\nAttacking Scaling Factor\nEvery EO data has its specific Scale Factor information. Here from the (HowUseScale?), Landsat Level 2 images have Surface Reflectance and Surface Temperature scale factors…\n\n\n\n\n\nLandsat Level 2 Scale Factor Source: (HowUseScale?)\n\n\n\n\nWe then apply these scaling factors in a function.\n\nfunction applyScaleFactors(image) {\n  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n  var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\n  return image.addBands(opticalBands, null, true)\n              .addBands(thermalBands, null, true);\n}\n\nAnd now we apply the scale function to our image collection, and apply to median reducer as well.\n\nvar oneimage_scale = oneimage.map(applyScaleFactors);\n\n//apply the median reducer from above\nvar oneimage_scale_median = oneimage.reduce(ee.Reducer.median());\n\nWe still have 19 bands but only 1 image. Each band is a median of all the image layers we used.\n\n\n5.1.1.2 Mapping\n\nvar vis_params = {\n  bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'],\n  min: 0.0,\n  max: 0.3,\n};\n\n// addlayer to map\nMap.addLayer(oneimage_scale_median, vis_params,'True Color (432)');\n\n\n\n\n\n\n\n\n\n\nAnd now we can see!\n\n\n5.1.1.3 Mosaicking\nJoining 2 tiles together. From the image above you can see clear lines where the tiles overlap (due to date of collection + atmospheric correction applied). We’re gna get rid of the lines.\n\n//Using the image collection before taking the medians.\nvar mosaic = oneimage_scale.mosaic();\n\nvar vis_params2 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0.0,\n  max: 0.3,\n};\n\nMap.addLayer(mosaic, vis_params2, 'spatial mosaic');\n\nNot much better, the demarcations are even more obvious..\nAndy: instead of using the reducer, the easier and better way is just to take the mean of all the images.\n\nvar meanImage = oneimage_scale.mean();\n\nMap.addLayer(meanImage, vis_params2, 'mean');\n\nHere the image is much better blended… But what’s the point of the median reducer???\n\n\n5.1.1.4 Clipping\nNow we want to clip to the shape of Delhi\n\nvar clip = meanImage.clip(india)\n  .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']);\n\nvar vis_params3 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0,\n  max: 0.3,\n};\n\n// map the layer\nMap.addLayer(clip, vis_params3, 'clip');\n\n\n\n\n\n\n\n\n\n\nClipped!\n\n\n5.1.1.5 Making and Adding Texture Layer\nWe want to compute texture using glcmTexture(). To do this we need to multiply the surface reflectance so it doesn’t reduce to 1 and 0 (bc the glcmtexture function only read integers). Note: there’s a lot of data here, if unresponsive, reduce bands.\n\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\n  \n// Add back to the map, but change the range values  \nMap.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\n\n\n\n\n\n\n\n\n\nWe made a texture layer! This can then be used in conjuncture with other bands for analysis.\n\n\n5.1.1.6 Principle Component Analysis\nRefer to Week 3 Correction for more PCA content.\nNeed to look at this section….\n\n// Scale and band names\nvar scale = 30;\nvar bandNames = glcm.bandNames();\n\nvar region = india.geometry();\nMap.centerObject(region, 10);\nMap.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\n\nprint(region, \"india_geometry\")\n// this region is the outline of Dehli\n\n// mean center the data and SD stretch the princapal components \n// and an SD stretch of the principal components.\nvar meanDict = glcm.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n});\nvar means = ee.Image.constant(meanDict.values(bandNames));\nvar centered = glcm.subtract(means);\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\nNow we have what we need for PCA.\n\n// This function accepts mean centered imagery, a scale and\n// a region in which to perform the analysis.  It returns the\n// Principal Components (PC) in the region as a new image.\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n\n  // Compute the covariance of the bands within the region.\n  var covar = arrays.reduceRegion({\n    reducer: ee.Reducer.centeredCovariance(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n  });\n\n  // Get the 'array' covariance result and cast to an array.\n  // This represents the band-to-band covariance within the region.\n  var covarArray = ee.Array(covar.get('array'));\n\n  // Perform an eigen analysis and slice apart the values and vectors.\n  var eigens = covarArray.eigen();\n\n  // This is a P-length vector of Eigenvalues.\n  var eigenValues = eigens.slice(1, 0, 1);\n  // This is a PxP matrix with eigenvectors in rows.\n  \n  var eigenValuesList = eigenValues.toList().flatten()\n  var total = eigenValuesList.reduce(ee.Reducer.sum())\n  var percentageVariance = eigenValuesList.map(function(item) {\n  return (ee.Number(item).divide(total)).multiply(100).format('%.2f')\n    })\n  \n  print(\"percentageVariance\", percentageVariance)  \n\n  var eigenVectors = eigens.slice(1, 1);\n\n  // Convert the array image to 2D arrays for matrix computations.\n  var arrayImage = arrays.toArray(1);\n\n  // Left multiply the image array by the matrix of eigenvectors.\n  var principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage);\n\n  // Turn the square roots of the Eigenvalues into a P-band image.\n  var sdImage = ee.Image(eigenValues.sqrt())\n    .arrayProject([0]).arrayFlatten([getNewBandNames('sd')]);\n\n  // Turn the PCs into a P-band image, normalized by SD.\n  return principalComponents\n    // Throw out an an unneeded dimension, [[]] -> [].\n    .arrayProject([0])\n    // Make the one band array image a multi-band image, [] -> image.\n    .arrayFlatten([getNewBandNames('pc')])\n    // Normalize the PCs by their SDs.\n    .divide(sdImage);\n};\n\n\n// Get the PCs at the specified scale and in the specified region\nvar pcImage = getPrincipalComponents(centered, scale, region);\n\nNow from PercentageVariance we know that the first 2 layers explains almost 90% of the variance.\n\n\n\n\n\n\n\n\n\nSo we can print out the first 2 layers:\n\nMap.addLayer(pcImage, {bands: ['pc2', 'pc1'], min: -2, max: 2}, 'PCA bands 1 and 2');\n\nOr if we want to whole stack:\n\n for (var i = 0; i < bandNames.length().getInfo(); i++) {\n   var band = pcImage.bandNames().get(i).getInfo();\n   Map.addLayer(pcImage.select([band]), {min: -2, max: 2}, band);\n }"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nSince what we learnt this week was mainly understanding how Google Earth Engine made using already open source Earth Observation data so accessible, I want to highlight the projects that were made possible because of this plaform.\nIn particular, citizen journalism website Bellincat has made use of Google Earth Engine to do detailed environmental analysis, as well to support its wider work detailing breaches of international humanitarian law in conflicts such as the war in Yemen.\nIn 2020, Bellingcat released data illustrating the fast decline of water levels in the Quitobaquito Springs on the US-Mexico border, making use of Google Earth Engine data to access, filter and analyse satellite data of the springs over multiple timescale. The analysis was fairly simple, using the Palmer Drought Severity Index as a measure for drought condition. However it is the low barrier to entry enabled by GEE has made geodata journalism much more widespread and democratised.The journalist also pointed to the open-source nature and ease of use of the programme as a key benefit.\nExpanding a little further, it is exactly because of this accessibility, and that knowledge and techniques are not as heavily gatekept (although quite specific skillsets are still required), many are using GEE for activism. Bellingcat has an entire section focusing on the invasion in Ukraine because remote sensing data allow for close monitoring without having to be in the field. Although I am sure geodata journalism is not single-handedly enabled by Google itself, it definitely played a significant role in exposing people to geodata analysis.\nAnd to go on: GEE makes it reallly easy to make and distribute interactive map. This is especially helpful to communicate with non-data trained individuals (without having to send them a stack of QGIS files), it is simple, contained, intuitive and engaging.\n\n\n\n\n\n\n\n\nI mean look at this. It’s pretty cool."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGoogle Earth Engine has made processing and analysing Earth Observation data much more accessible. This allows individuals to access and process large scale geospatial data without the need for powerful hardwares and softwares. Because everything is hosted on the server, this enables scalability processes involving larger datasets that otherwise would be too big for desktop-based processing. GGE also streamlines the analysis process, eliminating the need for switching between multiple softwares, integrating instantaneous visualisation, data sourcing and scripting in one space. The vast volume of images available on GEE also reduces time spent on locating and sourcing geospatial data drastically.\nSince GGE is already a web-hosted platform, it makes distributing and presenting analysis/maps much simpler. This is great when communicating with non-geospatial trained clients and enables more geospatial output/discussion.\nAlthough looking back onto the codes we used to process images on R, the codes are much shorter than codes on GEE (eg: code for PCA on R is around 4 lines?!). However this is the trade off of having a web-based platform that enables streamline image sourcing and visualization – and this requires Javascript. R is still more computationally more robust, but ultimately it depends on what you want to achieve! And who says you can’t use both!"
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "Week 6 is about classification! When we get an image from satellites, we need the programme to be able to identify types of land cover for masses of data. While we can’t do this manually, we need to rely on Machine Learning methods."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Introduction to Machine Learning\nMachine Learning is the science of computer modelling of learning process.\nMachine learning models use a type of inductive inference where the knowledge base (rule of thumbs) are learned from specific historical example (the training data), and these general conclusion to predict future.\n\n6.1.1.1 Classification & Regression Trees (CART): Classification\nClassification Trees\n\nWhen a decision tree classify things to categories.\nClassify data into 2+ discrete categories, split into further branches until all categories of decision have been made.\n\nINSERT IMAGE\n\nA good classification tree should be multi layered because just one independent vary would often result in impure results (where the predictive power of the independent variable is not 100% accurate)\nThe more relevant dependent variables in the tree, the less impure the result should be, and the stronger the predictive accuracy.\n\nHow do we know what order we put our dependent variables in the classification tree?\n\nWe calculate a Gini Impurity for each variable, and the one with the lowest impurity becomes the root.\nwe dont expect the leaves from the root node to be pure, so we calculate the the Gini impurity of the remaining variables, and choose the variable with the lowerst Gini impurity score, split the node and so on, until nodes become leaves.\n\nRegression Trees\n\nWhen decision tree predicts numeric, continous discrete values\nWhen linear 1 relationship does not fit data, we split the data into smaller subset, and run several different regressions for each chunk\n\nINSERT IMAGE\nHow do we know where to cut?\n\nSections are divided based on thresholds (nodes) and the SSR (Sum of Square Residuals) is calcuated.\nAgain, ones with lowest SSR becomes the root, and so on.\nOutcome: each leaf should represent the value that is close to the data\n\n\n\n\n\n\n\n\n\n\nPublic Enemy: Overfittiing\nSubsetting and dividing dataset too much could lead to overfitting — meaning the model is so fine tuned to the detail on the dataset it is learning from, it is unable to effectly predict outcome with a different dataset.\n\n\n\n\n\n\n\n\n\nBias: difference between predicted value and true value — bad a being precise\nVariance: variability of model for a given point — bad a generalising\nYou want a bit of both!\nPreventative measures:\n\nLimit how the tree grows — set minimum of at least 20pixel per leaf\nWeakest Link pruning:\n\n\n\n\n\n\n\n\n\n\nCalculate SSR for each tree. From no leaf removal to more leaves removal\nIt is expected that as more leaves are removed, the SSR gets bigger. The point is so that the model doesn’t fit the training data too well anyway\nWith each tree’s SSR, we calcuate the Tree Score – the lower the better.\nTree Score = SSR + αT\nT = number of leaves\nα = tree penalty. The more leaves removed, the higher the α.\nHow to decide on α?\nBuild a full size (training and testing) regression tree, wher α becomes 0, where tree score is the lowest. Repeat and get a different α values for each tree.\n\nReturn to the training data, and apply α values from before, which dictakes where the data is split\n\nDo this process 10 times for cross validation — the value of α that gives the smallest ~SSR is the final value → slect the tree that used the full data with that specific alpha\n\n\n\n6.1.2 Random Forest\nMany decision trees from 1 set of data.\nDecision trees on their own are pretty inaccurate, not flexible when classifying new samples.\n\nRandom Forests are simple, but also very adaptable when met with new data, improving accuracy\n\n\n\n\n\n\n\n\n\nValidation data: different from OOB, not in the original dataset at all.\nBootstrapping: Where you randomly select samples, and you’re allowed to pick the same sample more than once.\n\n\n6.1.3 Image Classification\nOkay, so how do we apply what we learned above onto image classification, and how do they relate?"
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nExamples of image classification\nSupport Vector Machine & Maximum Likelihood: which is better?\n(Otukei?) explored and compared Decision Trees, Support Vector Machines and Maximum Likelihood techniques when it comes to classifying land cover change in Uganda . They highlighted that expert knowledge is essential in creating the thresholds and boundaries when building analysis, but this is often lacking in the Global South. They proposed to use data mining approaches to determine decision threshold for these analyses.\nUganda has undergone huge land cover changes, where wetlands have been converted to crop fields to support livelihoods. The was conducted to evaluate the land cover change that has happened between 1981 and 2001.\n\n\n\n\n\n\n\n\n\nAbove you can see the classification outputs for each methods. All 3 methods performed well with accuracies above 85%, with decision trees performing slightly better with overall accuracy of 93%.\nIt is important to note however, each classification methods has it’s pros and cons. Often which method you choose to use depends on the nature of your data and what output you are looking for. And sometimes, it might be down to the overall accuracy to decide.\n\n6.2.1 Identifying Land Cover and Land Use\nClassification methods are especially good to track rapid urbanisation and LULC where the physical environment undergoes a drastic transformation over time and space. This study by (fashae?) tracks LULC of the city of Ibadan, Nigeria from 1984 to 2019 using random forest machine learning classifier on GEE. The study also tracks the land surface temperature, to monitor the effects of ubranisation on urban temperature.\nData\nThe study used Landsat series TM, ETM+ and OLI satellite images from December 1984, December 2002 and January 2019. They extracted band 1 to 5 (visible, near-infrared, shortwave infrareds) of Landsat ETMS +. Thermal bands ETM+ (band 6) and OLI band 10 were used to derive Land Surface data. Additional data on annual rainfall from within that period were also included.\nOutcome At the end, 5 prominent land use/land cover types were identified: heavy forest, light forest, light built-up area, heavy built-up area, and water bodies.\nThe RF highest classification accuracy was achieved with ten trees on bands 1, 2, 3, 4, 5, and 7 (TM and ETM+) and bands 2, 3, 4, 5, 6, and 7 (OLI) of the pre-processed images to generate the land use/land cover pattern."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nReally enjoyed this week! This week we looked into the early days methods of classification, first diving into the concept of decision trees and random forests.These methods are very intuitive to me. The highest performing variable will be set as the root to maximise chance of an accurate classification. And we need to make a LOT of trees so that we remove stochatiscity – Makes sense! But it got a little complicated when it came to image classification.\nData poverty – continuation of colonisation trhough knowledge."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Classification II",
    "section": "",
    "text": "Land cover classification, Continued"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nShould we bother with creating new ones or use pre-classified data?\n\nGlobeLand30\nESA Climate Change Initiatiec annual global land cover\nDynamic world — near real time classification of sentinel 2 10m\nGoogle building data\nMODIS – quite coarse\n\nThe answer is, depends.\n\n7.1.1 Object Based Image Analysis, Sub Pixel Analysis, Accuracy Assessment\nHere is a flow chart/mind map that describes and explains Object Based Image Analysis, Sub pixel Analysis and briefly touches on Accuracy Assessment."
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nIdentifying objects and features\nOBIA is essentially a step up from last week’s supervised and unsupervised image classification techniques, and is a more contemporary and accurate method in comparison as it uses spectral and contextual information.\n\n\n\n\n\n\n\n\n\nUsing OBIA to track unplanned urban development such as spread of densely packed informal settlements is extremely effective as it can add more complex classes that are defined by spatial and hierarchical relationships, given a more complex land composition.\n(Fallatah2018?) used objected-based random forest classification alongside Machine Learning techniques to identify informal settlements in Jeddah, western Saudi Arabia, using GeoEye-1 Multi Spectral Image with 0.5m panchromatic resolution and 2m multispectral. The paper critiqued OBIA is too time consuming and not viable to for mapping large scale data such as the entire city of Jeddah. The OBIA-ML fusion technique therefore extract the classified and grouped pixels into segments. These segments are then used as training data to for the machine learning model and execute subsequent classification.\nRandom forest classification was used, where dataset was bootstrapped and 1/3 were left as OOB for validation.\nThey used very-high-resolution (VHR) imagery and terrain data, and produced 3 land classifications (environment, settlements and object) and 14 indicators (14!!!!!) that provide more details into the building density, road accessibility, where water way be gathering and proximity to social services and hazardous terrains.\nThis is pretty incredible. To be able to detect so many features in one go goes to show the power of OBIA.\n\n\n\n\n\n\n\n\n\nWhen compared to the OBIA only approach at a 5km^2 scale, the study found the ML approach generated marked improvement in formal settlement (77% to 85%) and road network (73% to 95%) identification. However vegetation accuracy fell from 100% to 60%. But they ultimately found at a city-scale, the ML approach performance improved with overall accuracy of 91% compared to the OBIA only approach at 83%.\nThis was a very interesting paper to read as it ties a lot of what I’ve learnt in this class and the CASA Data science module together First classifying images and objects through OBIA, then use that classification and apply machine learning techniques.\nAccuracy Assessment\nA big part of classification is to validation the outcome through accuracy assessment and confusion matrix. In Ghorbanzadeh’s work on landslide detection using OBIA and deep learning techniques, they visualised their accuracy assessment as a map. Through this visualisation you can clearly see model is generating the highest overall accuracy across different terrains.\n\n\n\n\n\n\n\n\n\nInterestingly, both Ghorbanzadeh and Fallatah’s work suggest that OBIA accuracy is substantially increased when used in conjuncture with machine learning methods. Ghorbanzadeh went on and highlighted OBIA is highly dependent on expert knowledge in order to get satisfactory results, and deep learning techniques could be a solution to this dependence."
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nTo me, this was probably one of the hardest week in terms of content. It’s difficult to get my head around how we are able to build such powerful machines, especially when it’s just a few lines of code on GEE.\nOverall, it is really impressive to be able to gather information on aspects of urban life that would not be otherwise available through census surveys or traditional surveying methods, especially in least developed or developing countries. However my problem with classification is intra-class diversity and variations. On the extreme, a religious building in Rome is going to look very different to one in the Congo. How we do then make sure we have comprehensive and inclusive set of labelled data to hand when we conduct classification? And that the classification is tailored and contextualised to local environments, instead of a researcher based in the US looking to evaluate LULC in Cambodia, without real knowledge of the nuance and context of their built environment? This highlights the need for the expert (rule of thumb person) to be involve throughout the analysis so that no broad assumptions are made. What is really interesting is that (Douglass2020?) highlighted that many researchers now prefer to use automated ML-OBIA methods within the remote sensing archaeology field, exactly because it helps remove human conscious or unconscious biases, where confounding assumptions could be applied. Although automated analysis could still have their limitations and assumptions, these biases are often explicit and reproducible. But again, all machine learning and automated techniques are built from the initial knowledge base/rule of thumb, so I’m still quite skeptical. Is human bias avoidable at all?"
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Urban Heat Island",
    "section": "",
    "text": "This week we look into the Urban Heat Island Effect, policies to combat it across the world how we can use remote sensing techniques to predict, prevent and protect."
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "8  Urban Heat Island",
    "section": "8.1 Application",
    "text": "8.1 Application\n\n8.1.1 The General Situation, What is it?\nThe impacts of the Urban Heat Island (UHI) effect have been difficult to ignore in recent years. Alongside rising global temperatures, higher temperatures experienced in urban areas pose a serious risk toward the health and wellbeing of urban populations. In the UK, the five-day heat wave in July 2022 was associated with 2,800 deaths in over-65s across the country as temperatures rose as high as 40C in central London.\n\n\n\n\n\n(UrbanHeatIsland?)\n\n\n\n\n\nThere are various factors that contributes to UHI:\n\nHigh density buildings in the urban core that replaced natural covers such as trees and natural water feature drastically reduce cities’ capacity to increase their albedo.\nDark impermeable surfaces such as tarmac roads and black roofs contributes to overheating as dark colours only absorb the heat, instead of reflecting it elsewhere.\nFeedback Loop: the hotter it gets, the more energy cities will use to cool itself down. This means frequent uses of air conditioners which, in the process of generating cool air, is actively pumping out hot air onto the streets."
  },
  {
    "objectID": "week8.html#what-are-the-impacts",
    "href": "week8.html#what-are-the-impacts",
    "title": "8  Urban Heat Island",
    "section": "8.2 What are the impacts?",
    "text": "8.2 What are the impacts?\n\n8.2.1 Economic\nEstrada, Botzen, and Tol (2017) estimated the % lost from UHI in each GHG level scenario. The lowest GHG scenario still predicts 0.71% to be lost in 2050\n\n\n8.2.2 Environmental\nMentioned briefly above, the hotter it is, the more energy requires to keep people cool. Santamouris et al. (2015) found that each degree of ambient temperature rise increases the peak electricity load around 0.45 and 4.6%. Also taking into account that many countries rely on oil and gas suppliers to supply energy. And from what we experienced (and experiencing) with the geopolitics with Russia, this is bad news for the environment and the wallet.\n\n\n8.2.3 Social: The already disadvantaged gets it the worst\nHarlan et al. (2013) conducted a comprehensive study identifying social and environmental predictors of heat vulnerability in Arizona. The study found deprived areas, especially those with majority black populations and areas of spatial deprivation , where dwellings are considered overcrowded, are particularly vulnerable to heat-related deaths.\nOften, it is exactly these poor urban areas that have the least access to green and blue covers and further away from hospitals for medical assistance Prosdocimi and Klima (2020) found that risk of death is increased by 1.02% per km of distance. Hello redlining!"
  },
  {
    "objectID": "week8.html#global-policies",
    "href": "week8.html#global-policies",
    "title": "8  Urban Heat Island",
    "section": "8.3 Global Policies",
    "text": "8.3 Global Policies\nGlobal policies like the New Urban Agenda, Sustainable Development Goals, COP26 (which is now funded by oil tycoons!) all have general references to the UHI problem, however these global framework are often vague. Which in a way is fair enough because it needs to be applicable for all nations across economic strengths and different infrastructures. These documents are also often extremely long, so not very user friendly either. But this means the responsibility falls onto nation states and city level governments."
  },
  {
    "objectID": "week8.html#local-policies",
    "href": "week8.html#local-policies",
    "title": "8  Urban Heat Island",
    "section": "8.4 Local Policies",
    "text": "8.4 Local Policies\n\n\n\n\n\n\n\n\nPlace\nStrategy\nOutcomes\n\n\n\n\nBarcelona\nSuperblock\nIncreased footfall and consumption, less pollutants, less cars, a lively walkable neigbourhood\n\n\nMedellin\nGreen Corridors\ntransformed undefined spaces that encouraged anti-social behaviours into welcoming spaces, increase quality of life, general cooling effect– but not near where people live…\n\n\nSydney Western Suburbs\nTurn Down the Heat Strategy\nThe first real guide from a city level that highlights the need to address UHI.\nBut provided no specifics. Yes we need to mitigate and prevent, but where? how? how much? who?\n\n\nBaltimore\ntree vouchers\nThis pushes the responsibilities towards city dwellers, when in fact large scale top down policies needs to be enforced by the government\n\n\nFremantle\nUrban forest Plan\nyay for data driven policy! But they only used 1 month’s data. Really should be using aggregate.\n\n\nPerth Met Area\n1955 requirement for 10% of open space\nOpen space != green space…"
  },
  {
    "objectID": "week8.html#application-1",
    "href": "week8.html#application-1",
    "title": "8  Urban Heat Island",
    "section": "8.5 Application",
    "text": "8.5 Application\n\n\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017. “A Global Economic Assessment of City Policies to Reduce Climate Change Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nHarlan, Sharon L., -Barreto Juan H. Declet, William L. Stefanov, and Diana B. Petitti. 2013. “Neighborhood Effects on Heat Deaths: Social and Environmental Predictors of Vulnerability in Maricopa County, Arizona.” Environmental Health Perspectives 121 (2): 197–204. https://doi.org/10.1289/ehp.1104625.\n\n\nProsdocimi, Diogo, and Kelly Klima. 2020. “Health Effects of Heat Vulnerability in Rio de Janeiro: A Validation Model for Policy Applications.” SN Applied Sciences 2 (12): 1948. https://doi.org/10.1007/s42452-020-03750-7.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015. “On the Impact of Urban Heat Island and Global Warming on the Power Demand and Electricity Consumption of BuildingsA Review.” Energy and Buildings, Renewable Energy Sources and Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Duque, Juan C., Jorge E. Patino, Luis A. Ruiz, and Josep E.\nPardo-Pascual. 2015. “Measuring Intra-Urban Poverty Using Land\nCover and Texture Metrics Derived from Remote Sensing Data.”\nLandscape and Urban Planning 135 (March): 11–21. https://doi.org/10.1016/j.landurbplan.2014.11.009.\n\n\n“Economic Growth and Trade |\nKenya.” Mon, 02/13/2023 - 14:17. U.S. Agency for\nInternational Development.\nhttps://www.usaid.gov/kenya/economic-growth-and-trade.\n\n\nElkhrachy, Ismail. 2022. “Flash Flood Water Depth Estimation\nUsing SAR Images, Digital Elevation Models, and\nMachine Learning Algorithms.” Remote\nSensing 14 (3): 440. https://doi.org/10.3390/rs14030440.\n\n\n“ESA and Climate.” n.d.\nhttps://www.esa.int/Applications/Observing_the_Earth/Space_for_our_climate/ESA_and_climate.\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017.\n“A Global Economic Assessment of City Policies to Reduce Climate\nChange Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nGreen, Norman. 1957. “Aerial Photographic\nInterpretation and the Social Structure of the\nCity.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nHabitat, UN. n.d. “Kenya: Nairobi Urban Profile |\nUN-Habitat.” UN Habitat.\nhttps://unhabitat.org/kenya-nairobi-urban-profile.\n\n\nHarlan, Sharon L., -Barreto Juan H. Declet, William L. Stefanov, and\nDiana B. Petitti. 2013. “Neighborhood Effects on Heat Deaths:\nSocial and Environmental Predictors of Vulnerability in Maricopa County,\nArizona.” Environmental Health Perspectives 121 (2):\n197–204. https://doi.org/10.1289/ehp.1104625.\n\n\nLeonita, Gina, Monika Kuffer, Richard Sliuzas, and Claudio Persello.\n2018. “Machine Learning-Based Slum Mapping in Support of Slum\nUpgrading Programs: The Case of Bandung City, Indonesia.”\nRemote Sensing 10 (10): 1522. https://doi.org/10.3390/rs10101522.\n\n\nLi, G., and Q. Weng. 2007. “Measuring the Quality of Life in City\nof Indianapolis by Integration of Remote Sensing and Census\nData.” International Journal of Remote Sensing 28 (2):\n249–67. https://doi.org/10.1080/01431160600735624.\n\n\nMatricardi, Eraldo A. T., David L. Skole, Marcos A. Pedlowski, Walter\nChomentowski, and Luis Claudio Fernandes. 2010. “Assessment of\nTropical Forest Degradation by Selective Logging and Fire Using\nLandsat Imagery.” Remote Sensing of\nEnvironment 114 (5): 1117–29. https://doi.org/10.1016/j.rse.2010.01.001.\n\n\n“Nairobi.” n.d. C40 Cities.\nhttps://www.c40.org/cities/nairobi/.\n\n\nPandey, Prem Chandra, Nicholas J. Tate, and Heiko Balzter. 2014.\n“Mapping Tree Species in Coastal Portugal Using\nStatistically Segmented Principal Component Analysis and\nOther Methods.” IEEE Sensors Journal 14\n(12): 4434–41. https://doi.org/10.1109/JSEN.2014.2335612.\n\n\nPatino, Jorge E., and Juan C. Duque. 2013. “A Review of Regional\nScience Applications of Satellite Remote Sensing in Urban\nSettings.” Computers, Environment and Urban Systems 37\n(January): 1–17. https://doi.org/10.1016/j.compenvurbsys.2012.06.003.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002.\n“Monitoring the Composition of Urban Environments Based on the\nVegetation-Impervious Surface-Soil (VIS) Model by Subpixel\nAnalysis Techniques.” International Journal of Remote\nSensing 23 (20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\nProsdocimi, Diogo, and Kelly Klima. 2020. “Health Effects of Heat\nVulnerability in Rio de Janeiro: A Validation Model for Policy\nApplications.” SN Applied Sciences 2 (12): 1948. https://doi.org/10.1007/s42452-020-03750-7.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015.\n“On the Impact of Urban Heat Island and Global Warming on the\nPower Demand and Electricity Consumption of BuildingsA\nReview.” Energy and Buildings, Renewable Energy Sources\nand Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052.\n\n\n“Site Suitability Evaluation for Urban\nDevelopment Using Remote Sensing, GIS and\nAnalytic Hierarchy Process (AHP) |\nSpringerLink.” n.d.\nhttps://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\nSriwongsitanon, Nutchanart, Kritsanat Surakit, and Sansarith\nThianpopirug. 2011. “Influence of Atmospheric Correction and\nNumber of Sampling Points on the Accuracy of Water Clarity Assessment\nUsing Remote Sensing Application.” Journal of Hydrology\n401 (3): 203–20. https://doi.org/10.1016/j.jhydrol.2011.02.023.\n\n\nSultana, Sabiha, and A. N. V. Satyanarayana. 2020. “Assessment of\nUrbanisation and Urban Heat Island Intensities Using Landsat Imageries\nDuring 2000 2018 over a Sub-Tropical Indian City.”\nSustainable Cities and Society 52 (January): 101846. https://doi.org/10.1016/j.scs.2019.101846.\n\n\nSutton, Paul C. 2003. “A Scale-Adjusted Measure of\n‘Urban Sprawl’ Using Nighttime Satellite\nImagery.” Remote Sensing of Environment, Urban\nRemote Sensing, 86 (3): 353–69. https://doi.org/10.1016/S0034-4257(03)00078-6.\n\n\nWang, Jianghao, Yong Ge, Gerard B. M. Heuvelink, Chenghu Zhou, and Dick\nBrus. 2012. “Effect of the Sampling Design of Ground Control\nPoints on the Geometric Correction of Remotely Sensed Imagery.”\nInternational Journal of Applied Earth Observation and\nGeoinformation 18 (August): 91–100. https://doi.org/10.1016/j.jag.2012.01.001.\n\n\nWEBER, C., and J. HIRSCH. 1992. “Some Urban Measurements from\nSPOT Data: Urban Life Quality Indices.”\nInternational Journal of Remote Sensing 13 (17): 3251–61. https://doi.org/10.1080/01431169208904116."
  }
]