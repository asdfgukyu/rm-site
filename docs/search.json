[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing Cities and Environment",
    "section": "",
    "text": "Hello! Welcome to my learning diary for CASA0023 Remote Sensing Cities and Environments at the Centre for Advance Spatial Analysis, UCL London.\nI am a socio-cultural geographer, a producer in the culture sector and a spatial data scientist (!) . I got my undergraduate degree at the London School of Economics in Human Geography where I studied topics from urban planning, economic geography, and international development to investigating urban socio-spatial dynamics and role of the creative sector in urban space.\n\nAfter graduation, I entered the cultural sector where I worked in theatre, dance, visual art and moving images programme curation and production in Hong Kong and London for three years.\nAt CASA, I am looking to develop my geographic knowledge, gain technical skills and - hopefully - enter the field of urban sustainability. I am particularly interested in the topics of public housing, social justice and climate resilience !\n\n\nThis learning diary is the assignment output of CASA00023 Remote Sensing Cities and Environment. This book is broken down by weeks, each with a different learning objective.\nThis book is created from R markdown and executable code."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Welcome to Remote Sensing! This week we will cover the basic grounds – what is light? What is an electromagnetic waves, how do satellites work?"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Lecture Overview: What is Remote Sensing?\n\n\n\n\n\n\n\n\n\n\n1.1.2 Electromagnetic Spectrum\nThe electromagnetic spectrum is made up of thousands of bands, including visible light, UV, infrared, radar, FM, TV and short wave.\n\n\n\n\n\n\n\n\n\nSource: GISGeography (2017)\n\nThe earth’s surface either absorbs energy or transmits energy.\nThe colour we see is the visible light waves that is reflected off of the object. Apple is red because it reflects red and absorbs all other visible light.\n\n\n\n1.1.3 Resolutions of remote sensing images\nSpatial: The size of a raster grid per pixel (cm/m). The smaller the measure, the more detailed the image.\nSpectral: The number of bands from the electromagnetic spectrum being surveyed. Often earth surfaces require multispectral data to form a true colour image.\n\ni.e. green vegetation mostly requires red and near-infrared bands to detect, whereas soil requires mid-infrared bands (6 and 7) to be detected; bodies of water can be detected mostly within visible light (RBGs).\nLandsat data surveys visible light, near infrared and short wave infrared.\n\nAn example from the practical: The below scatter image was produced from sentinel data of Dhakar, Bangladesh. Band 4 = Red Band 8 = NIR * High NIR and Low Red - high vegetation since veg peaks in NIR (see above) * Low red Low NIR - Wet soil.\n\n\n\n\n\n\n\n\n\nTemporal: How frequently the data is collected. Often there is a direct trade-off between pixel resolution and update frequency – the higher the resolution, the lower the update frequency. Good rm data is spenny!!\nRadiometric: Able to identify difference in light or reflectance of Earth surface.\n\nThe higher the bit, the higher the depth, the higher the ability to detect texture.\n\nData format: Generally raster, but depending on sensor.\n\nLiDAR is point data in x, y and z (height) → good for elevation models.\n\n\n\n\n\n\n\n\n\n\nSource: Jensen (1986)\nA bit of thinking: Applications of varying temporal and spatial resolution, what occasion it’s best for and what satellite provides that spatial resolution. An interesting point is RM data for emergency responses require fairly granular spatial resolution and frequent temporal resolution – so as to track minute changes in landscapes. However as mentioned above, there are direct trade offs between temporal and pixel resolution. For satellites to provide both high temporal and spatial resolution requires huge sums of cost and investment. With growing threats from the climate crisis on the urban landscape – do we currently have the capacity to effectively monitor damages and respond on time?\n\n\n1.1.4 Factors influencing Electromagnetic waves\nA lot of things happen from when electromagnetic wave is emitted from sun/satellites and when it hits the earth surface. And these things could interfere with the images and data we get.\nRayleigh Scattering: Scattering of waves off of molecules in the air (the atmosphere).\n\nBlue waves are smaller, making it easier to scatter → sky = blue.\nHigher the scatter/absorption, deeper the colour. Deep ocean is dark because there are more water molecules to scatter and absorb waves → no reflection.\n\nBidirectional Reflectance Distribution Function (BRDF):\n\nchanging angles of sensors and levels of illumination\nearth surface that is smooth/diffuse that causes reflectance to go in different directions.\nShadows: Backscattering - sun behind observer | forward scattering - sun opposite observer.\n\nPolarization (SAR data):\n\nEMR waves with 2 waves oscillating perpendicularly. How they reflect depends on texture of the earth surface, moisture, salinity, density, orientation.\nSingle: same polarization transmitted and received\nDual: transmit one, get another\nQuad: transmit and receive up to 4 types.\n\n\n\n1.1.5 Practical: Landsat, Sentinel, QGIS, SNAP\nData Source: Sentinel Data: Copernicus Open Access Hub Landsat Data: Earth Explorer USGS Boundary Data (for masking): https://gadm.org/\nColour compositions: True Colour: colours we see with our eyes B2, B3, B4. False Colour: composite of waves human eyes cannot see. * Infrared: B8, B4, B3. Plants reflect NIR and green light and absorbing red. * Agriculture: B11, B8, B2. Detecting healthy vegetation in dark green * Moisture:(B8A-B11)/(B8A+B11). Detecting water stressed."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction",
    "section": "1.2 Application",
    "text": "1.2 Application\nSince the emergence of accessible Landsat Satellite images in 1967, earth data has been used for a wide range of purposes including tracking land use, urbanisation, drought, wildfires, biomass changes and other natural and human caused changes (USGS, nd).\n\n1.2.0.1 Environment\nThe Intergovernmental Panel on Climate Change stated earth-observing satellites are a critical and valuable tool to track changes and improving climate predictions (“ESA and Climate” (n.d.)). Coupled with substantial environmental changes in recent decades, remote sensing data has allowed changes to be tracked and analysed over the last century. Sultana and Satyanarayana (2020) have used satellite imagery to assess the rate of urbanisation and urban heat island intensities in urban India. Matricardi et al. (2010) analysed the effects of tropical forest degradation as a result of logging and fire, and implemented policy recommendation accordingly, taking advantage of the extensive spectral bands available. Extensive reports by international climate driven bodies have used earth data to measure glacier and sea ice decline, sea level rise and climate modelling.\n\n\n1.2.0.2 Urban Development\nDevelopment of urban areas can be measured with medium to high spatial resolution satellite images including SPOT, Landsat, and Aster, providing a large mass of data on urban growth (Patino and Duque (2013)). Sutton (2003) measured the sprawl of cities using nighttime satellite imagery, using lights as a proxy for urban activities. Elkhrachy (2022) has specifically used SAR data to detect depth of flash flood water in risk zones. “Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink” (n.d.) used earth data and Analytic Hierarchy Process technique to evaluate site suitability for urban development. They specifically looked for geomorphology, transport network, land use/cover and access to ground water. 1 meter spatial resolution images from from IKONOS data was used.\n\n\n\n\n\n\n\n\n\nSource: “Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink” (n.d.)\n\n\n1.2.0.3 Assisting social analysis\nSatellite imagery has allowed for a spatial perspective when it comes to studying social processes such as urban poverty, quality of life (WEBER and HIRSCH (1992)), residential desirability (Green (1957)). Generating estimation about the urban population was reported to be one of the top 5 recurrent research theme within remote sensing urban environments Phinn et al. (2002). For example, Li and Weng (2007) derived environmental variables such as greenness, temperature from Landsat EMT+ as proxies to material and environmental welfare and crowdedness. This is integrated with US census data to generate a Quality of Life Index. Duque et al. (2015) used Quickbird images of 0.6m spatial resolution (extremely high res!!) to generate a intra-urban Slum index. This was executed through per-pixel classification of urban texture and structures."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nRemote sensing data has in a way revolutionised how people approach spatial analysis, providing an unprecedented amount of data about the earth’s surface with lrelatively ow barriers to access compared to previous available methods, such as costal surveying. This has been especially true since remote sensing data became publicly available, democratising access.\nUtilising the varying spectral properties of earth surfaces and objects, our understanding and ability to analyse urban areas has significantly improved, with scientists more easily able to map high density buildings, transport networks and urban vegetation. RM data essentially removes the need to physically surface overviews of urban characteristics (although detailed, high resolution analysis still relies on manual surveying).\nAlthough powerful, earth data is often used in conjunction with other data, especially demographic, social and economic data for urban analysis to translate into urban policies. For example, satellite imaging can be used to map certain visible characteristics of urban poverty, alongside census data to give a more nuanced picture.\nThere is a wide range of analysis that could be done with RM data, including regression analysis, neural network deep learning, principal component analysis and classification. The options are endless!!!!\n\n\n\n\n\nDuque, Juan C., Jorge E. Patino, Luis A. Ruiz, and Josep E. Pardo-Pascual. 2015. “Measuring Intra-Urban Poverty Using Land Cover and Texture Metrics Derived from Remote Sensing Data.” Landscape and Urban Planning 135 (March): 11–21. https://doi.org/10.1016/j.landurbplan.2014.11.009.\n\n\nElkhrachy, Ismail. 2022. “Flash Flood Water Depth Estimation Using SAR Images, Digital Elevation Models, and Machine Learning Algorithms.” Remote Sensing 14 (3): 440. https://doi.org/10.3390/rs14030440.\n\n\n“ESA and Climate.” n.d. https://www.esa.int/Applications/Observing_the_Earth/Space_for_our_climate/ESA_and_climate.\n\n\nGISGeography. 2017. “Why the Atmospheric Window Matters in Earth Science.” https://gisgeography.com/atmospheric-window/.\n\n\nGreen, Norman. 1957. “Aerial Photographic Interpretation and the Social Structure of the City.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nJensen, J. R. 1986. “Introductory Digital Image Processing: A Remote Sensing Perspective.” https://www.osti.gov/biblio/5166368.\n\n\nLi, G., and Q. Weng. 2007. “Measuring the Quality of Life in City of Indianapolis by Integration of Remote Sensing and Census Data.” International Journal of Remote Sensing 28 (2): 249–67. https://doi.org/10.1080/01431160600735624.\n\n\nMatricardi, Eraldo A. T., David L. Skole, Marcos A. Pedlowski, Walter Chomentowski, and Luis Claudio Fernandes. 2010. “Assessment of Tropical Forest Degradation by Selective Logging and Fire Using Landsat Imagery.” Remote Sensing of Environment 114 (5): 1117–29. https://doi.org/10.1016/j.rse.2010.01.001.\n\n\nPatino, Jorge E., and Juan C. Duque. 2013. “A Review of Regional Science Applications of Satellite Remote Sensing in Urban Settings.” Computers, Environment and Urban Systems 37 (January): 1–17. https://doi.org/10.1016/j.compenvurbsys.2012.06.003.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002. “Monitoring the Composition of Urban Environments Based on the Vegetation-Impervious Surface-Soil (VIS) Model by Subpixel Analysis Techniques.” International Journal of Remote Sensing 23 (20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\n“Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink.” n.d. https://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\n“Site Suitability Evaluation for Urban Development Using Remote Sensing, GIS and Analytic Hierarchy Process (AHP) | SpringerLink.” n.d. https://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\nSultana, Sabiha, and A. N. V. Satyanarayana. 2020. “Assessment of Urbanisation and Urban Heat Island Intensities Using Landsat Imageries During 2000 2018 over a Sub-Tropical Indian City.” Sustainable Cities and Society 52 (January): 101846. https://doi.org/10.1016/j.scs.2019.101846.\n\n\nSutton, Paul C. 2003. “A Scale-Adjusted Measure of ‘Urban Sprawl’ Using Nighttime Satellite Imagery.” Remote Sensing of Environment, Urban Remote Sensing, 86 (3): 353–69. https://doi.org/10.1016/S0034-4257(03)00078-6.\n\n\nWEBER, C., and J. HIRSCH. 1992. “Some Urban Measurements from SPOT Data: Urban Life Quality Indices.” International Journal of Remote Sensing 13 (17): 3251–61. https://doi.org/10.1080/01431169208904116."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Portfolio Tools",
    "section": "",
    "text": "This week’s learning diary is to produce a Xarigan presentation and host it on a Quarto website. The content of the presentation includes 9 slides on Landsat 8 and 9, providing overview of the satellites (Summary), notable academic papers that have utilised data from these satellites (Application) and individual reflection."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "This week is about image corrections, including geometric correction, atmospheric correction, relative correction, absolute correction, empirical line correction, orthorectification correction, mosaicking, texturing and PCA.\nCode provided is in R."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary"
  },
  {
    "objectID": "week3.html#data-correction",
    "href": "week3.html#data-correction",
    "title": "3  Corrections",
    "section": "3.2 Data Correction",
    "text": "3.2 Data Correction\nSatellite data isn’t perfect, will have flaws and we need to fix it before we get into it, yuh.\n\n3.2.1 Geometric Correction\nProcess of removing geometric distortions caused by factors such as sensor perspective (off nadir), terrain relief (hill v flat ground), Wind (on plane) and Earth’s curvature and rotation.\n\n\n\n\n\n\n\n\n\n\nImages:\n\n3.2.1.1 Solution\nGround Control Points (GPS) to match satellite images to a reference datasets — another map, GPS data etc, using regression.\n\nForward Mapping: we have the xy in a correct image, xiyi in the uncorrected data, and change the data to it.\n\nbut the point is randomly placed on the correct image — not ideal\n\nBackward Mapping: predicting the wrong image with the correct image — more accurate, QGIS.\n\ntakes every point of the correct image and maps it onto the uncorrected image\n\n\nRMSE and Resampling\nNormally RMSE is set as 0.5, but you might want to add more GCPs to reduce RMSE.\nDuring this, data might be slightly shifted → so must resample the final raster by aligning via the nearest neighbour, linear, cubic. But grid cells might not align due to resolution etc etc.\n\n\n\n3.2.2 Atmospheric Correction\n\n3.2.2.1 Mainly scattering & topographic attenuation\nAdjacency Effect: reflective surfaces bleeds into other pixels caused by scattering, making the image hazy and reduces contrast.\n Image: Wang et al. (2012)\nWhen and when not to correct:\n\n\n\n\n\n\n\nUnnecessary\nNecessary\n\n\n\n\nClassification of a single image\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\n\n\nIndependent classification of multi date imagery\nUsing spectral signatures through time and space\n\n\nSingle dates data\n\n\n\nAlready Composited images\n\n\n\n\nBUT : Andy corrects it all anyway, just in case\n\n\n3.2.2.2 Solution\nRelative Correction\nTake a really dark pixel ( often the ocean) so that it can be assumed that it does not reflect the atmosphere at all, and subtract it to each pixel as a baseline.\nPsuedo Invariant Features (PIF)\n\nfrom different images to identify features that don’t change (carparks)\ntake regression, where y is the base image, apply model.\nbase model often is the middle one in time series.\n\nAbsolute Correction\n\nChange digital brightness values into a scaled surface reflectance via atmospheric radiative transfer models. This is done to the whole image\nBut this is difficult to do bc needs a lot of data and money.\n\nEmpirical Line Correction\n\nGo out to the field at take measurements using a field spectrometer, but you need to be at the right time a place where the satellite is right above…\nThis is also essentially done through linear regression\n\n\n\n\n3.2.3 Orthorectification Correction\nMake things nadir. This would be used if satellite passes adjacent to a mountain top instead of directly above it.\n\n\n\nOrthorectification of a mountain top to nadir. Source: “What Is Orthorectified Imagery?” (n.d.)\n\n\nOften uses cosine correction to calculate sun’s zenith and incidence angle\n\n\n3.2.4 Radiometric Calibration\nSatellites capture image brightness and is stored as Digital Number, which has no units and difficult to use!\nRadiometric Calibration is converting DN to spectral radiance.\nAfter all of that…\nThere is Landsat ARD - surface reflectance that is already corrected…\nBut it’s good to know anyway and not all data are ARD (drone images, v high resolution images)"
  },
  {
    "objectID": "week3.html#data-joining",
    "href": "week3.html#data-joining",
    "title": "3  Corrections",
    "section": "3.3 Data Joining",
    "text": "3.3 Data Joining\n\n3.3.1 Mosaicking\nSays what it does on the can! Just like feathering and merging, we are joining 2 or more images together.\nThe images must have some overlapping, or else there’ll be gaps in your map. The overlapping will be dealt with through feathering (blending) so that seamlines are not visible.\nMerging code:\n\nm1 <- terra::mosaic(listlandsat_9i, listlandsat_9ii, fun=\"mean\")"
  },
  {
    "objectID": "week3.html#image-enhancement",
    "href": "week3.html#image-enhancement",
    "title": "3  Corrections",
    "section": "3.4 Image Enhancement",
    "text": "3.4 Image Enhancement\nTo emphasize/exaggerate certain spectral traits. ### Contrast Enhancement\nDifferent materials don’t reflect varying energy back — making it hard to differentiate between things. Images are also designed to avoid saturation in DN.\n\nImage stretching applied to DN\n\n\n3.4.1 Ratio\nDifference between 2 spectral bands that have a certain spectral response – making it easier to identify certain landscape features. This is the remote sensing index, index that refers to a specific item, and uses simple formula to get them.\nRefer to Index Database for more!! There is an index for virtually everything on earth. From soil type, tree health, moisture level, rock/metal type etc etc…\nHere we’re extracting healthy vegetation, formula from Normalized Difference Vegetation Index. Band 5 - Band 4 (red)\n\nm1_NDVI <- (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 - m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4 ) / (m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5 + m1$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4)\n\nm1_NDVI %>%\n  plot(.)\n\n\n\n\n\n\n\n\n\n\nThe greener, there more healthy vegetation there is. Since this is EO image of Dhaka (aka flood zone), vegetation is only present further to the north.\nThis is to filter out features that has higher NDVI score.\n\nveg <- m1_NDVI %>%\n  terra::classify(., cbind(-Inf, 0.2, NA))\n\n\n\n3.4.2 Filtering\nFiltering refers to any kind of moving window operation (zooming out) to our data, saved as a separate raster file, either low or high pass filters.\n\n\n3.4.3 Texture\nUse glcm package to select 8 texture measures.\n\nCan specify size of moving window here\nspecify shift in co-occurency — if there are multiple shifts — will return mean for each pixel.\n\nThis will take 7-10mins!!\n\nglcm <- glcm(band4_raster,\n                   window = c(7, 7),\n                   #shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n                   statistics = c(\"homogeneity\"))\n\nINSERT CODE\n\n\n3.4.4 Data Fusion\nappend new raster data onto existing data OR merge several bands and make new easter dataset\nHere: merging the texture measure (glcm) and the original raster\n\n# for the next step of PCA we need to keep this in a raster (and not terra) format...\nm1_raster <- stack(m1)\n\nFuse <- stack(m1_raster, glcm)\n\n\n\n3.4.5 PCA\nreduce dimensionality of data!\nTo scale data, aka compare data that isnt measured in the same way (spectral bands 4 and 5) and textural data - use the scale function to standardise deviation.\nTo get the mean: use scale = FALSE We can also set the number of samples for PCA\n\nlibrary(RStoolbox)\n\nFuse_3_bands <- stack(Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B4, Fuse$LC09_L2SP_137043_20230126_20230128_02_T1_SR_B5, Fuse$glcm_homogeneity)\n\nscale_fuse<-scale(Fuse_3_bands)\n\npca <- rasterPCA(Fuse, \n                 nSamples =100,\n                 spca = TRUE)\n\n\n\n\n\n\n\n\n\n\nHere Comp 1 & 2 explains 0.81% of the variance. Often this is enough for analysis, so we extract only these 2.\n\n\n\n\n\n\n\n\n\nThis is the output of just layer 1."
  },
  {
    "objectID": "week3.html#a-little-about-data-format",
    "href": "week3.html#a-little-about-data-format",
    "title": "3  Corrections",
    "section": "3.5 A little about data format",
    "text": "3.5 A little about data format\nLandsat data are collected in rows and paths made up of grids of images.\nData is are in tiers and levels.\nTier: Tier 1 denotes best quality, Tier 2 are good but with some clouds that affects radiometric calibration, covering GCPs.\nLevel: Level 1 is delivered through DN, Level 2 has surface reflectance and surface temperature, Level 3 are specific products ie Burned Area, surface water extent."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Corrections",
    "section": "3.6 Application",
    "text": "3.6 Application\nWe outlined generally how these corrections and enhancements are executed. However when it comes to application, there are lots of debates around how best to correct/enhance an image.\nFor example, Wang et al. (2012) found we choose and design the Ground Control Points (GCPs) have strong effects on the accuracy of geometric correction. They used a universal kriging model-based sampling method that takes into account the spatial auto-covariance of regression residual, and extracts results accordingly. They found that the more disperse and even the distribution of the GCPs, the higher the geometric correction precision.\nAcademics also develop new methods of correction and enhancements specifically to extract earth features they want and accessibility of certain methods. Pandey, Tate, and Balzter (2014) use PCA to map tree species in coastal Portugal depending on the tree species’ reflectance signatures. He highlighted the high cost involved to do this using GCPs, and that the increasing temporal and spectral frequency of earth data made developing automatic image registration software possible. At the end 15 PC layers contained 99.42% of the information of the original hyperspectral image.\nSometimes you don’t know if an image needs to be corrected or not if there are no obvious signs of haze or clouds visible to us. In a similar vein to reduce costly ground observation data (but also to test whether atmospheric correction (AC) is needed for improving the reliability of the estimated values of 2 key clear water parameters), Sriwongsitanon, Surakit, and Thianpopirug (2011) evaluated the influence of atmospheric correction and number of sampling points on the accuracy of water clarity assessment. They collected data on clarity and sediment parameters at 80 ground observation points as reference and used three Landsat 5 TM images to conduct the experiment in the largest lake in Thailand. They found AC has a statistically significant influence over the max and min values of the sediment parameter and clarity parameter, making the images more accurate in assessing water clarity, thus encouraged to be applied to when assessing clarity of water. They also concluded that only 32/80 of the observation points were needed for the satellite image to obtain a reliable assessment as a result of AC, instead of all 80. (wohoo!)"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.7 Reflection",
    "text": "3.7 Reflection\nUnderstanding how satellite images are tweaked and handled before they could actually be used for analysis feels the same as data cleaning before we go into EDA. Although cumbersome at times, I feel this is the most effective way to get to know data before conducting analysis. It’s also generally good practice to understand how values are generated through by calculating them step by step, rather than just one line of code provided by a package. We will eventually encounter data that isn’t corrected. It’s good to at least to know generally how to approach correction. I’m also looking forward to GEE and see how the platform streamlines the process.\nThe possibilities with Earth Observation data seems to be… endless? Essentially anything activities larger than 10 by 10m can be detected on satellite images. That thought in itself is quite overwhelming, because when you can do everything, where do you start?\nIt’s been very useful to know how these correction and enhancement methods work before we dive straight into GEE with ARD. Surprisingly I didn’t find this week’s content that overwhelming (compared to week 7, just you wait). In contrast I really felt it laid the necessary foundation for me to understand how one would process earth observation data. I feel more confident knowing how to deal with earth observation data, in case I ever need to deal with raw images.\n\n\n\n\nPandey, Prem Chandra, Nicholas J. Tate, and Heiko Balzter. 2014. “Mapping Tree Species in Coastal Portugal Using Statistically Segmented Principal Component Analysis and Other Methods.” IEEE Sensors Journal 14 (12): 4434–41. https://doi.org/10.1109/JSEN.2014.2335612.\n\n\nSriwongsitanon, Nutchanart, Kritsanat Surakit, and Sansarith Thianpopirug. 2011. “Influence of Atmospheric Correction and Number of Sampling Points on the Accuracy of Water Clarity Assessment Using Remote Sensing Application.” Journal of Hydrology 401 (3): 203–20. https://doi.org/10.1016/j.jhydrol.2011.02.023.\n\n\nWang, Jianghao, Yong Ge, Gerard B. M. Heuvelink, Chenghu Zhou, and Dick Brus. 2012. “Effect of the Sampling Design of Ground Control Points on the Geometric Correction of Remotely Sensed Imagery.” International Journal of Applied Earth Observation and Geoinformation 18 (August): 91–100. https://doi.org/10.1016/j.jag.2012.01.001.\n\n\n“What Is Orthorectified Imagery?” n.d. https://www.esri.com/about/newsroom/insider/what-is-orthorectified-imagery/."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "This week focuses on how we may utilise insights gained from Earth Observation analysis to assist local, regional and national government to implement data-drive policies, whilst increasing compliance to urban/global agendas."
  },
  {
    "objectID": "week4.html#case-study-informal-settlements-flood-risks-in-nairobi-kenya",
    "href": "week4.html#case-study-informal-settlements-flood-risks-in-nairobi-kenya",
    "title": "4  Policy",
    "section": "4.1 Case Study: Informal Settlements & Flood risks in Nairobi, Kenya",
    "text": "4.1 Case Study: Informal Settlements & Flood risks in Nairobi, Kenya\n\n4.1.1 Context\n\n\n\n\n\n\n\n\n\nSource: Global Partnership for Result-Based Appraoaches (n.d.)\n\n4.1.1.1 Informal Settlement Expansion\n\nUntil the Covid-19 pandemic, Nairobi was one of the fastest growing urban economies in Africa with annual average GDP growth of 5.9% between 2010 - 2018 ( “Economic Growth and Trade | Kenya” (2023) ) The GDP of the city amounted to 36 billion USD ( “Nairobi” (n.d.) ).\nDespite rapid economic growth, the city has been unable to provide housing infrastructure for its increasing population. The spoils of growth have not yet been used to support the city’s sustainable expansion.\n75% of urban population growth in Nairobi is accounted for by informal settlements, and the proportion of urban population living in slums is predicted to double in the next 15 years.\nInformal settlements cover 5% of total residential land of the city but house half of the city’s total population (UN Habitat (n.d.) ).\n2/3 of Kenyans continue to live in poverty, making less than 3.2 GBP per day.\n70% Kenyan families are chronically vulnerable to food and nutrition insecurity and preventable diseases.\nNairobi is also extremely vulnerable to impact of the climate crisis – leading to food insecurity, reducing access to clean water, and exposing residents to increasingly frequent instances extreme heat and preventable diseases.\n\n\n\n4.1.1.2 Flood Risk\n\nAround 22,000 Kiberans live within 30m of the Ngong River, where over 50% of the residents reported their homes were flood during the 2015 long rains. Mulligan et al. (2017)\nClimate change is due to exacerbate Nairobi rainfall, with rainfall projected to be increase by 1/3. Cook et al. (2020)\nDespite risks, informal settlements continue to expand towards the river as those areas are often less regulated, and residents encounter less resistance building towards that area.\n\n\n\n\n4.1.2 International Framework\nSustainable Development Goals\n\n\n\n\n\n\n\n\n\nSource: (unitednationsCommunicationsMaterialsn.d?).\nThe Sustainable Development Goals are a set of 17 objectives that serve as a ‘blueprint to a to achieve a better and more sustainable future for all’, devised and led by the United Nations. The SDGs pushes for sustainable development that recognises the interconnectedness of social, economic and environmental aspect of society.\nRelevant goals:\nUN SDG02: End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\n\nTarget 02.1: By 2030, end hunger and ensure access by all people, in particular the poor and people in vulnerable situations, including infants, to safe, nutritious and sufficient food all year round.\nIndicator: Prevalence of moderate or severe food insecurity in the population, based on the Food Insecurity Experience Scale (FIES).\n\nUN SDG06: Ensure availability and sustainable management of water and sanitation for all.\n\nTarget 06.2: By 2030, achieve access to adequate and equitable sanitation and hygiene for all and end open defecation, paying special attention to the needs of women and girls and those in vulnerable situations.\nIndicator: Proportion of population using (a) safely managed sanitation services and (b) a hand-washing facility with soap and water.\n\nUN SDG11: Make cities and human settlements inclusive, safe, resilient and sustainable.\n\nTarget 11.1: By 2030, ensure access for all to adequate, safe and affordable housing and basic services and upgrade slums.\nIndicator: Proportion of urban population living in slums, informal settlements or inadequate housing.\n\n\n\n4.1.3 Urban-level framework\nNairobi Climate Action Plan 2020-2050\n\nNairobi has set out 15 climate resilience actions to strength the city against extreme weather, of which pertained very little detail onto how laid actions would be implemented.\n\nRelevant actions include:\n\n4.1.3.1 Action 13: Increase access to climate resilience programmes.\n\n\n\n\n\n\n\n\n\nSource: “Nairobi Climate Action Plan 2020-2050 Summary Booklet | Nairobi City County” (2022)\n\nHow the city of Nairobi aims to move towards such goals is unclear from this document.\nGeospatial technology (GIS, satellite imagery) is mentioned only once, where the local authority acknowledges that the lack of GIS technology means that they are unable to provide an accessible and wide-spread urban transit system.\nThis shows the Nairobi government is unable at present to effectively harness Earth Observation data to push forward their urban climate agenda.\nThe document also seems to encourage residential house building in climate sensitive areas.\nSlum mapping — see where slums will expand and provide amenities accordingly."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nInformal settlements in Nairobi are recognised as a serious issues by the city level government and national government, and is referenced by the United Nations as a worsening problem.\nInformal settlements need to be identified easily, at low cost and with increasing frequency, so that the local government is able to understand the direction of their expansion and population variations within the settlements.\nGeospatial mapping would enable local authorities to build much-needed sanitation infrastructure in areas of high and increasing population density. An up-to-date understanding of the growing population in informal settlements could provide much-needed information for social policymakers for wider programmes of healthcare, education or other public services.\nEarth observation data would also allow the government to identify areas of environmental vulnerability so that they are able to concentrate limited resources on regulating or halting the further expansion of informal settlements in the most environmentally sensitive areas.\n\n4.2.1 Slum identification\n\n\n\n\n\n\n\n\n\nApproach\nPurpose\nData\nReferences\n\n\n\n\nLULC\nTo identify the spatial distribution of informal settlements, Buid- up areas with high population density, bodies of water, barren land, road networks.\nLandsat TM/ Landsat 8/Rapid Eye Images\nBadmos et al. (2018) used LULC and Landsat images and generated 6 land classification: water, vegetated area, open space, road, slum and other urban, through 2009 to 2015.\nThey were then able to track how the slums are encroaching other unsafe spaces (water) which could increase mortality.\n\n\nEnvironment (Flood Risk) Assessment\nTo identify areas of low elevation and areas susceptible to flooding.\nNASADEM Global Elevation Model\nHistorical rainfall data (SM2RAIN-ASCAT)\nDe Risi et al. (2013) Established a general framework for conduction flood risk assessment for informal settlements.\nUsing Digital Elevation Models alongside historical rainfall data, a geospatial climate model is produced to identify areas of high flood risks.\n\n\nInfrastructure Assessment\nIdentify quality and type of infrastructure in informal settlements to identify areas vulnerable to flood risk. Often Informal settlement infrastructure are not up to housing code.\nVery High Resolution images: Landsat TM, SPOT\nAn alternative is open sourced data: OSM and medium Resolution satellite imageries\nAssarkhaniki, Sabri, and Rajabifard (2021) noted that often developing nations do not have the funds and resources to access high resolution images. This is especially true the Nairobi. OSM layered over medium resolution Landsat 8 can provide a much more accessible method to achieve resilience and SDGs in informal settlements. Geometric features can be extracted and different building types can be classified.\n\n\n\nInsights gain from the above geospatial analysis can enable local government to make data informed policy. These information forms the foundation of sustainable resilience.\n\n4.2.1.1 Methodology\nOwusu et al. (2021)’s paper highlights the ethical considerations when producing insight from geospatial analysis with the aims of policy application.\n\n\n\n\n\n\n\n\n\nSource: Owusu et al. (2021)\nThe image above is what they deem as key deliverables when working with clients. I think strikes a good balance between focusing on technicality in remote sensing, but also considering the wider policy application context and consequences."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nWithout the necessary public policy interventions or structures in place, rapid economic growth can coexist with increasingly severe housing, environmental and health issues. The right understanding of the urban landscape, how it is changing and what the demographic and economic profile of residents are can be used to solve some of those problems.\nGeospatial data is useful not just to evaluate the existing status of built environments but as a tool to observe almost real-time changes in a rapidly expanding urban environment. This provides signifcant advantages for policymakers who are often required to dedicate limited resources to solving rapidly changing problems, moreso in areas such as Nairobi where there is a fast-growing population and increasingly severe problem of informal settlements.\nEarth observation data is not always widely used in the policy space, and is - particularly in this instance - sometimes not seriously acknowledged by governments as a major tool for urban policymaking, despite its relatively low cost to access and high potential to improve the understanding of the urban landscape. It is unclear why this is the case, and what could be done to draw greater attention to geospatial data within policymaking at a local level.\n\n\n\n\n\nAssarkhaniki, Zahra, Soheil Sabri, and Abbas Rajabifard. 2021. “Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement.” Big Earth Data 5 (4): 497–526. https://doi.org/10.1080/20964471.2021.1948178.\n\n\nBadmos, Olabisi S., Andreas Rienow, Daniel Callo-Concha, Klaus Greve, and Carsten Jürgens. 2018. “Urban Development in West AfricaMonitoring and Intensity Analysis of Slum Growth in Lagos: Linking Pattern and Process.” Remote Sensing 10 (7): 1044. https://doi.org/10.3390/rs10071044.\n\n\nCook, Kerry H., Rory G. J. Fitzpatrick, Weiran Liu, and Edward K. Vizy. 2020. “Seasonal Asymmetry of Equatorial East African Rainfall Projections: Understanding Differences Between the Response of the Long Rains and the Short Rains to Increased Greenhouse Gases.” Climate Dynamics 55 (7): 1759–77. https://doi.org/10.1007/s00382-020-05350-y.\n\n\nDe Risi, R., F. Jalayer, F. De Paola, I. Iervolino, M. Giugni, M. E. Topa, E. Mbuya, A. Kyessi, G. Manfredi, and P. Gasparini. 2013. “Flood Risk Assessment for Informal Settlements.” Natural Hazards 69 (1): 1003–32. https://doi.org/10.1007/s11069-013-0749-0.\n\n\n“Economic Growth and Trade | Kenya.” 2023. https://www.usaid.gov/kenya/economic-growth-and-trade.\n\n\nGlobal Partnership for Result-Based Appraoaches. n.d. “Kenya: Assessment of Kayole-Soweto Informal Settlement | the Global Partnership for Results-Based Approaches (GPRBA).” https://www.gprba.org/activities/kayole-soweto-informal-settlement.\n\n\nMulligan, Joe, Jamilla Harper, Pascal Kipkemboi, Bukonola Ngobi, and Anna Collins. 2017. “Community-Responsive Adaptation to Flooding in Kibera, Kenya.” Proceedings of the Institution of Civil Engineers - Engineering Sustainability 170 (5): 268–80. https://doi.org/10.1680/jensu.15.00060.\n\n\n“Nairobi.” n.d. https://www.c40.org/cities/nairobi/.\n\n\n“Nairobi Climate Action Plan 2020-2050 Summary Booklet | Nairobi City County.” 2022. https://nairobi.go.ke/climate-action-plan-2020-2050/.\n\n\nOwusu, Maxwell, Monika Kuffer, Mariana Belgiu, Tais Grippa, Moritz Lennert, Stefanos Georganos, and Sabine Vanhuysse. 2021. “2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS.” In, 5700–5703. https://doi.org/10.1109/IGARSS47720.2021.9553570.\n\n\nUN Habitat. n.d. “Kenya: Nairobi Urban Profile | UN-Habitat.” https://unhabitat.org/kenya-nairobi-urban-profile."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Introduction to Google Earth Engine",
    "section": "",
    "text": "Because this week’s material is mainly to get acquainted with GEE using the skills and methodologies we learnt in previous weeks – this week’s learning diary will mainly feature GEE scripts, so I can refer here for main codes for basic analysis."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nWhat is GEE?\nA geospatial processing service, allow for large scale analysis - EO data are all stored on the server Handy because it maps out the output immediately — good for visualisation\nGoogle does things a little differently…\nNaming Things…\n\n\n\nGee\nR\n\n\n\n\nImage\nRaster\n\n\nFeature\nVector\n\n\nImageCollection\nFeatureCollection (multiple polygons)\n\n\n\nUses Javascript\nCan’t run individual code chunk → must run the whole script!\nClient v Server Side\n\n\n\n\n\n\n\nClient\nServer\n\n\n\n\nFrontend\nBackend\n\n\nOur scripts\nprocessing the code\n\n\nlight! Nothing store locally\nstoring all EO data (anything with .ee in it)\n\n\n\nNotes:\n\nDon’t loop something on the server, looping is computationally very inefficient and loop doesn’t know what’s inside the .ee\nBut a function (ie mapping) is welcomed, so that it can be saved as an object\nMapping: make a function and apply to the entire collection\n\nonly loading the initially colelction once!\n\n\nScale (aka pixel resolution)\nMost things in GEE is aggregated, and GEE will automatically select the closest scale to your analysis and resample it.\nAlways set the scale parameters to what you need, if not, it will default to the zoom level of the map.\nAlways try to put in the scale:scale line\nProjection\nNo need to think about projection, until exporting it out of GEE\nAny new shapefile will be automatically transformed\nGEE converts all their OE data to WGS84 Mercator (EPSG3857). Operations of projections are determined by output — meaning they do the working figuring out what you need, and give it to you.\nObject Class\n\nGeometry: point, line, polygon with no attributes\nFeature: geometry with attribute table, single polygon\n\nThing to manipulate data with\n\nReducer: take loads of data to one thing (zonal statistics)\nJoin: can even join landsat and sentinel data!\nArray: spreadsheet\n\n\n\n\n\n\nObject class. Source: (ObjectsMethodsOverview?)\n\n\n\n\n\n5.1.1 Applying\n\n\n\n\n\nProcess of GEE analysis in Week 5 practical\n\n\n\n\n\n5.1.1.1 Loading In\nWhen loading in ee.ImageCollection , we need to/can specify:\n\n.filterDate(’start date’, ‘end date’)\n.filter(ee.Filter.calendarRange(1, 2, 'month'))\n.filterBounds(PlaceName)\n.filter(ee.Filter.lt(”CLOUD_COVER”, 0.1))\n\nAdd Features & Geometries\nImport GADM boundary map that has Delhi boundaries, in this case column GID_1 row IND.25.1_1\n\nvar india = ee.FeatureCollection('users/asdfgukyu/india-2')\n    .filter('GID_1 == \"IND.25_1\"');\n\nLoad Landsat 9 data\nfilter by date, month, and bound. Each image has 19 bands, and when we add the map layer, with no filter on the bands to include.\n\nvar oneimage = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n  .filterDate('2020-01-01', '2022-10-10')\n  .filterBounds(india)  // Intersecting ROI\n  .filter(ee.Filter.lt(\"CLOUD_COVER\", 0.1));\n\nTrue Layer\nIf we want to get a true colour layer made with RGB.\n\nMap.addLayer(oneimage, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]})\n\nOtherwise, if we want all 19 bands:\n\nMap.addLayer(oneimage)\n\n\n\n\n\n\n\n\n\n\nBoth of the results show very dark images, but no clouds. We need to reduce all of these images so we get 1 that we can work with. We’re going ahead with the 19 bands here (oneimage).\nDeveloping an image reducer The method we used here is reducing by median, but there are better ways to do this, like percentile or seasonal methods.\n\nvar median = oneimage.reduce(ee.Reducer.median());\nprint(median, \"median\") //Print to Console\n\nAttacking Scaling Factor\nEvery EO data has its specific Scale Factor information. Here from the (HowUseScale?), Landsat Level 2 images have Surface Reflectance and Surface Temperature scale factors…\n\n\n\n\n\nLandsat Level 2 Scale Factor Source: (HowUseScale?)\n\n\n\n\nWe then apply these scaling factors in a function.\n\nfunction applyScaleFactors(image) {\n  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n  var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\n  return image.addBands(opticalBands, null, true)\n              .addBands(thermalBands, null, true);\n}\n\nAnd now we apply the scale function to our image collection, and apply to median reducer as well.\n\nvar oneimage_scale = oneimage.map(applyScaleFactors);\n\n//apply the median reducer from above\nvar oneimage_scale_median = oneimage.reduce(ee.Reducer.median());\n\nWe still have 19 bands but only 1 image. Each band is a median of all the image layers we used.\n\n\n5.1.1.2 Mapping\n\nvar vis_params = {\n  bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'],\n  min: 0.0,\n  max: 0.3,\n};\n\n// addlayer to map\nMap.addLayer(oneimage_scale_median, vis_params,'True Color (432)');\n\n\n\n\n\n\n\n\n\n\nAnd now we can see!\n\n\n5.1.1.3 Mosaicking\nJoining 2 tiles together. From the image above you can see clear lines where the tiles overlap (due to date of collection + atmospheric correction applied). We’re gna get rid of the lines.\n\n//Using the image collection before taking the medians.\nvar mosaic = oneimage_scale.mosaic();\n\nvar vis_params2 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0.0,\n  max: 0.3,\n};\n\nMap.addLayer(mosaic, vis_params2, 'spatial mosaic');\n\nNot much better, the demarcations are even more obvious..\nAndy: instead of using the reducer, the easier and better way is just to take the mean of all the images.\n\nvar meanImage = oneimage_scale.mean();\n\nMap.addLayer(meanImage, vis_params2, 'mean');\n\nHere the image is much better blended… But what’s the point of the median reducer???\n\n\n5.1.1.4 Clipping\nNow we want to clip to the shape of Delhi\n\nvar clip = meanImage.clip(india)\n  .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']);\n\nvar vis_params3 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0,\n  max: 0.3,\n};\n\n// map the layer\nMap.addLayer(clip, vis_params3, 'clip');\n\n\n\n\n\n\n\n\n\n\nClipped!\n\n\n5.1.1.5 Making and Adding Texture Layer\nWe want to compute texture using glcmTexture(). To do this we need to multiply the surface reflectance so it doesn’t reduce to 1 and 0 (bc the glcmtexture function only read integers). Note: there’s a lot of data here, if unresponsive, reduce bands.\n\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\n  \n// Add back to the map, but change the range values  \nMap.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\n\n\n\n\n\n\n\n\n\nWe made a texture layer! This can then be used in conjuncture with other bands for analysis.\n\n\n5.1.1.6 Principle Component Analysis\nRefer to Week 3 Correction for more PCA content.\nNeed to look at this section….\n\n// Scale and band names\nvar scale = 30;\nvar bandNames = glcm.bandNames();\n\nvar region = india.geometry();\nMap.centerObject(region, 10);\nMap.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\n\nprint(region, \"india_geometry\")\n// this region is the outline of Dehli\n\n// mean center the data and SD stretch the princapal components \n// and an SD stretch of the principal components.\nvar meanDict = glcm.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n});\nvar means = ee.Image.constant(meanDict.values(bandNames));\nvar centered = glcm.subtract(means);\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\nNow we have what we need for PCA.\n\n// This function accepts mean centered imagery, a scale and\n// a region in which to perform the analysis.  It returns the\n// Principal Components (PC) in the region as a new image.\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n\n  // Compute the covariance of the bands within the region.\n  var covar = arrays.reduceRegion({\n    reducer: ee.Reducer.centeredCovariance(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n  });\n\n  // Get the 'array' covariance result and cast to an array.\n  // This represents the band-to-band covariance within the region.\n  var covarArray = ee.Array(covar.get('array'));\n\n  // Perform an eigen analysis and slice apart the values and vectors.\n  var eigens = covarArray.eigen();\n\n  // This is a P-length vector of Eigenvalues.\n  var eigenValues = eigens.slice(1, 0, 1);\n  // This is a PxP matrix with eigenvectors in rows.\n  \n  var eigenValuesList = eigenValues.toList().flatten()\n  var total = eigenValuesList.reduce(ee.Reducer.sum())\n  var percentageVariance = eigenValuesList.map(function(item) {\n  return (ee.Number(item).divide(total)).multiply(100).format('%.2f')\n    })\n  \n  print(\"percentageVariance\", percentageVariance)  \n\n  var eigenVectors = eigens.slice(1, 1);\n\n  // Convert the array image to 2D arrays for matrix computations.\n  var arrayImage = arrays.toArray(1);\n\n  // Left multiply the image array by the matrix of eigenvectors.\n  var principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage);\n\n  // Turn the square roots of the Eigenvalues into a P-band image.\n  var sdImage = ee.Image(eigenValues.sqrt())\n    .arrayProject([0]).arrayFlatten([getNewBandNames('sd')]);\n\n  // Turn the PCs into a P-band image, normalized by SD.\n  return principalComponents\n    // Throw out an an unneeded dimension, [[]] -> [].\n    .arrayProject([0])\n    // Make the one band array image a multi-band image, [] -> image.\n    .arrayFlatten([getNewBandNames('pc')])\n    // Normalize the PCs by their SDs.\n    .divide(sdImage);\n};\n\n\n// Get the PCs at the specified scale and in the specified region\nvar pcImage = getPrincipalComponents(centered, scale, region);\n\nNow from PercentageVariance we know that the first 2 layers explains almost 90% of the variance.\n\n\n\n\n\n\n\n\n\nSo we can print out the first 2 layers:\n\nMap.addLayer(pcImage, {bands: ['pc2', 'pc1'], min: -2, max: 2}, 'PCA bands 1 and 2');\n\nOr if we want to whole stack:\n\n for (var i = 0; i < bandNames.length().getInfo(); i++) {\n   var band = pcImage.bandNames().get(i).getInfo();\n   Map.addLayer(pcImage.select([band]), {min: -2, max: 2}, band);\n }"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nSince what we learnt this week was mainly understanding how Google Earth Engine made using already open source Earth Observation data so accessible, I want to highlight the projects that were made possible because of this plaform.\nIn particular, citizen journalism website Bellingcat has made use of Google Earth Engine to do detailed environmental analysis, as well to support its wider work detailing breaches of international humanitarian law in conflicts such as the war in Yemen.\nIn 2020, Bellingcat released data illustrating the fast decline of water levels in the Quitobaquito Springs on the US-Mexico border ( Team (2020) ), making use of Google Earth Engine data to access, filter and analyse satellite data of the springs over multiple timescale. The analysis was fairly simple, using the Palmer Drought Severity Index as a measure for drought condition. However it is the low barrier to entry enabled by GEE has made geodata journalism much more widespread and democratised.The journalist also pointed to the open-source nature and ease of use of the programme as a key benefit.\nExpanding a little further, it is exactly because of this accessibility, and that knowledge and techniques are not as heavily gatekept (although quite specific skillsets are still required), many are using GEE for activism. Bellingcat has an entire section focusing on the invasion in Ukraine because remote sensing data allow for close monitoring without having to be in the field. Although I am sure geodata journalism is not single-handedly enabled by Google itself, it definitely played a significant role in exposing people to geodata analysis.\nAnd to go on: GEE makes it reallly easy to make and distribute interactive map. This is especially helpful to communicate with non-data trained individuals (without having to send them a stack of QGIS files), it is simple, contained, intuitive and engaging.\n\n\n\n\n\n\n\n\nI mean look at this. It’s pretty cool."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGoogle Earth Engine has made processing and analysing Earth Observation data much more accessible. This allows individuals to access and process large scale geospatial data without the need for powerful hardwares and softwares. Because everything is hosted on the server, this enables scalability processes involving larger datasets that otherwise would be too big for desktop-based processing. GGE also streamlines the analysis process, eliminating the need for switching between multiple softwares, integrating instantaneous visualisation, data sourcing and scripting in one space. The vast volume of images available on GEE also reduces time spent on locating and sourcing geospatial data drastically.\nSince GGE is already a web-hosted platform, it makes distributing and presenting analysis/maps much simpler. This is great when communicating with non-geospatial trained clients and enables more geospatial output/discussion.\nAlthough looking back onto the codes we used to process images on R, the codes are much shorter than codes on GEE (eg: code for PCA on R is around 4 lines?!). However this is the trade off of having a web-based platform that enables streamline image sourcing and visualization – and this requires Javascript. R is still more computationally more robust, but ultimately it depends on what you want to achieve! And who says you can’t use both!\n\n\n\n\nTeam, Investigative Tech. 2020. “The Disappearance of Quitobaquito Springs: Tracking Hydrologic Change with Google Earth Engine.” https://www.bellingcat.com/resources/2020/10/01/the-disappearance-of-quitobaquito-springs-tracking-hydrologic-change-with-google-earth-engine/."
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "Week 6 is about classification! When we get an image from satellites, we need the programme to be able to identify types of land cover for masses of data. While we can’t do this manually, we need to rely on Machine Learning methods."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Introduction to Machine Learning\nMachine Learning is the science of computer modelling of learning process.\nMachine learning models use a type of inductive inference where the knowledge base (rule of thumbs) are learned from specific historical example (the training data), and these general conclusion to predict future.\n\n6.1.1.1 Classification & Regression Trees (CART): Classification\nClassification Trees\n\nWhen a decision tree classify things to categories.\nClassify data into 2+ discrete categories, split into further branches until all categories of decision have been made.\nA good classification tree should be multi layered because just one independent vary would often result in impure results (where the predictive power of the independent variable is not 100% accurate)\nThe more relevant dependent variables in the tree, the less impure the result should be, and the stronger the predictive accuracy.\n\nHow do we know what order we put our dependent variables in the classification tree?\n\nWe calculate a Gini Impurity for each variable, and the one with the lowest impurity becomes the root.\nwe dont expect the leaves from the root node to be pure, so we calculate the the Gini impurity of the remaining variables, and choose the variable with the lowest Gini impurity score, split the node and so on, until nodes become leaves.\n\nRegression Trees\n\nWhen decision tree predicts numeric, continuous discrete values\nWhen linear 1 relationship does not fit data, we split the data into smaller subset, and run several different regressions for each chunk\n\nHow do we know where to cut?\n\nSections are divided based on thresholds (nodes) and the SSR (Sum of Square Residuals) is calculated.\nAgain, ones with lowest SSR becomes the root, and so on.\nOutcome: each leaf should represent the value that is close to the data\n\n\n\n\n\n\n\n\n\n\nPublic Enemy: Overfittiing\nSubsetting and dividing dataset too much could lead to overfitting — meaning the model is so fine tuned to the detail on the dataset it is learning from, it is unable to effectively predict outcome with a different dataset.\n\n\n\n\n\n\n\n\n\nBias: difference between predicted value and true value — bad a being precise\nVariance: variability of model for a given point — bad a generalising\nYou want a bit of both!\nPreventative measures:\n\nLimit how the tree grows – set minimum of at least 20pixel per leaf\nWeakest Link pruning:\n\n\n\n\n\n\n\n\n\n\nImage: The formidable Anne Robinson\nCalculate SSR for each tree. From no leaf removal to more leaves removal\nIt is expected that as more leaves are removed, the SSR gets bigger. The point is so that the model doesn’t fit the training data too well anyway.\nWith each tree’s SSR, we calculate the Tree Score (the lower the better).\nTree Score = SSR + αT\nT = number of leaves\nα = tree penalty. The more leaves removed, the higher the α.\nHow to decide on α?\nBuild a full size (training and testing) regression tree, where α becomes 0, where tree score is the lowest. Repeat and get a different α values for each tree.\n\nReturn to the training data, and apply α values from before, which dictates where the data is split\n\nDo this process 10 times for cross validation — the value of α that gives the smallest ~SSR is the final value → select the tree that used the full data with that specific alpha\n\n\n\n6.1.2 Random Forest\nMany decision trees from 1 set of data.\nDecision trees on their own are pretty inaccurate, not flexible when classifying new samples. Random Forests are simple, but also very adaptable when met with new data, improving accuracy\n\n\n\n\n\n\n\n\nValidation data: different from OOB, not in the original dataset at all.\nBootstrapping: Where you randomly select samples, and you’re allowed to pick the same sample more than once.\n\n\n6.1.3 Image Classification\nOkay, so how do we apply what we learned above onto image classification, and how do they relate?"
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nExamples of image classification\nSupport Vector Machine & Maximum Likelihood: which is better?\nOtukei and Blaschke (2010) explored and compared Decision Trees, Support Vector Machines and Maximum Likelihood techniques when it comes to classifying land cover change in Uganda . They highlighted that expert knowledge is essential in creating the thresholds and boundaries when building analysis, but this is often lacking in the Global South. They proposed to use data mining approaches to determine decision threshold for these analyses.\nUganda has undergone huge land cover changes, where wetlands have been converted to crop fields to support livelihoods. The was conducted to evaluate the land cover change that has happened between 1981 and 2001.\n\n\n\n\n\n\n\n\n\nAbove you can see the classification outputs for each methods. All 3 methods performed well with accuracies above 85%, with decision trees performing slightly better with overall accuracy of 93%.\nIt is important to note however, each classification methods has it’s pros and cons. Often which method you choose to use depends on the nature of your data and what output you are looking for. And sometimes, it might be down to the overall accuracy to decide.\nFor complex systems, non parametric approaches are often more flexible and data driven as they do not require any assumptions or mathematical models about the underlying probability distribution of your data.\nWithin more well researched fields, such as LULC and vegetation classification, Maximum Likehood tends to be more popular as there are often clear distinction between different feature classes.\n\n6.2.0.1 Monitoring invasive species using SVM\nGavier-Pizarro et al. (2012) did a really interesting and novel project using Landsat TM/ETM+ data and SVM to monitor the invasion of the Chinese tree glossy privet that is aggressively replacing native forests in Argentina, causing huge cause of concern regarding conservation. SVM was chosen simply because this approach has been proven to be effective in vegetation classification.\nLandsat TM/ETM+ data are only at 30m resolution, but these images have been successful in mapping invasion for single points in time that forms homogeneous patches larger than 0.5 hectares, given surround phenology of native species are different. Glossy Privets are much lower in luminosity compared to native vegetation.\n\n\n\n\n\n\n\n\n\nSource: Gavier-Pizarro et al. (2012)\nSince the classes are not linearly separable, a Gaussian kernal function was applied to gain the optimal values of C and gamma for SVM. These parameters were then used to classify the multitemporal stacks of Landsat images to map glossy privet invasion.\nI find this technique of mapping single points in time to overcome the problem of low spatial resolution very interesting. The authors did not mention if this approach has reduced the overall accuracy either. Another problem with is approach is that the spread of invasive species has to be quite prominent already for detection to occur. The study highlighted areas of mixed species/early stages were classified as native forest. This this analysis only allows for a reactive measure against the invasive expansion."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week we looked into the early days methods of classification, first diving into the concept of decision trees and random forests. These methods are very intuitive to me. I visualise this as a person walks down the street and decide if they want to go left or right at a junction. A path is then paved depending on the characteristics of the person: their ethnicity, social class, how they’re feeling that day.\n\n\n\n\n\n\n\n\n\nAndy ended this week’s lecture highlighting the accuracy and interpretability trade off between different classification methods. Coming from a social science background, I would intuitively choose a classifier that is easier to understand. My approach to data science is that insights gains are ultimately generated to inform policy making. The problem of the blackbox is concerning because when stakeholders, clients and even data scientists themselves don’t entirely understand how these insights are generated, this threaten the trustworthiness of this insight. I think as machine learning and deep learning continue to advance rapidly, increasing interpretability needs to be prioritised. Because utimately, data isn’t always correct. And if we don’t know how insights came to be, we wouldn’t know what went wrong and how we would fix it.\n\n\n\n\nGavier-Pizarro, Gregorio I., Tobias Kuemmerle, Laura E. Hoyos, Susan I. Stewart, Cynthia D. Huebner, Nicholas S. Keuler, and Volker C. Radeloff. 2012. “Monitoring the Invasion of an Exotic Tree (Ligustrum Lucidum) from 1983 to 2006 with Landsat TM/ETM+ Satellite Data and Support Vector Machines in Córdoba, Argentina.” Remote Sensing of Environment, Landsat Legacy Special Issue, 122 (July): 134–45. https://doi.org/10.1016/j.rse.2011.09.023.\n\n\nOtukei, J. R., and T. Blaschke. 2010. “Land Cover Change Assessment Using Decision Trees, Support Vector Machines and Maximum Likelihood Classification Algorithms.” International Journal of Applied Earth Observation and Geoinformation, Supplement Issue on \"Remote Sensing for Africa  A Special Collection from the African Association for Remote Sensing of the Environment (AARSE)\", 12 (February): S27–31. https://doi.org/10.1016/j.jag.2009.11.002."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Classification II",
    "section": "",
    "text": "More classification this week, but this time we’re looking at the most modern technique – Object Based Image Analysis. This means we move from raster grid cells to detecting objects according to their shapes and colours. We then look into how we make sure our classifications are accurate using the confusion matrix.\nLand cover classification, Continued"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nShould we bother with creating new ones or use pre-classified data?\n\nGlobeLand30\nESA Climate Change Initiatiec annual global land cover\nDynamic world — near real time classification of sentinel 2 10m\nGoogle building data\nMODIS – quite coarse\n\nThe answer is, depends.\n\n7.1.1 Object Based Image Analysis, Sub Pixel Analysis, Accuracy Assessment\nHere is a flow chart/mind map that describes and explains Object Based Image Analysis, Sub pixel Analysis and briefly touches on Accuracy Assessment."
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nIdentifying objects and features\nOBIA is essentially a step up from last week’s supervised and unsupervised image classification techniques, and is a more contemporary and accurate method in comparison as it uses spectral and contextual information.\n\n\n\n\n\n\n\n\n\nSource: GISGeography (2014)\nUsing OBIA to track unplanned urban development such as spread of densely packed informal settlements is extremely effective as it can add more complex classes that are defined by spatial and hierarchical relationships, given a more complex land composition.\nFallatah, Jones, and Mitchell (2020) used objected-based random forest classification alongside Machine Learning techniques to identify informal settlements in Jeddah, western Saudi Arabia, using GeoEye-1 Multi Spectral Image with 0.5m panchromatic resolution and 2m multispectral. The paper critiqued OBIA is too time consuming and not viable to for mapping large scale data such as the entire city of Jeddah. The OBIA-ML fusion technique therefore extract the classified and grouped pixels into segments. These segments are then used as training data to for the machine learning model and execute subsequent classification.\nRandom forest classification was used, where dataset was bootstrapped and 1/3 were left as OOB for validation.\nThey used very-high-resolution (VHR) imagery and terrain data, and produced 3 land classifications (environment, settlements and object) and 14 indicators (14!!!!!) that provide more details into the building density, road accessibility, where water way be gathering and proximity to social services and hazardous terrains.\nThis is pretty incredible. To be able to detect so many features in one go goes to show the power of OBIA.\n\n\n\n\n\n\n\n\n\nSource: Fallatah, Jones, and Mitchell (2020)\nWhen compared to the OBIA only approach at a 5km^2 scale, the study found the ML approach generated marked improvement in formal settlement (77% to 85%) and road network (73% to 95%) identification. However vegetation accuracy fell from 100% to 60%. But they ultimately found at a city-scale, the ML approach performance improved with overall accuracy of 91% compared to the OBIA only approach at 83%.\nThis was a very interesting paper to read as it ties a lot of what I’ve learnt in this class and the CASA Data science module together First classifying images and objects through OBIA, then use that classification and apply machine learning techniques.\nAccuracy Assessment\nA big part of classification is to validation the outcome through accuracy assessment and confusion matrix. In Ghorbanzadeh et al. (2022) work on landslide detection using OBIA and deep learning techniques, they visualised their accuracy assessment as a map. Through this visualisation you can clearly see model is generating the highest overall accuracy across different terrains.\n\n\n\n\n\n\n\n\n\nSource: Ghorbanzadeh et al. (2022)\nInterestingly, both Ghorbanzadeh and Fallatah’s work suggest that OBIA accuracy is substantially increased when used in conjuncture with machine learning methods. Ghorbanzadeh went on and highlighted OBIA is highly dependent on expert knowledge in order to get satisfactory results, and deep learning techniques could be a solution to this dependence."
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nTo me, this was probably one of the hardest week in terms of content. It’s difficult to get my head around how we are able to build such powerful machines, especially when it’s just a few lines of code on GEE.\nOverall, it is really impressive to be able to gather information on aspects of urban life that would not be otherwise available through census surveys or traditional surveying methods, especially in least developed or developing countries. However my problem with classification is intra-class diversity and variations. On the extreme, a religious building in Rome is going to look very different to one in the Congo. How we do then make sure we have comprehensive and inclusive set of labelled data to hand when we conduct classification? And that the classification is tailored and contextualised to local environments, instead of a researcher based in the US looking to evaluate LULC in Cambodia, without real knowledge of the nuance and context of their built environment? This highlights the need for the expert (rule of thumb person) to be involve throughout the analysis so that no broad assumptions are made. What is really interesting is that (Douglass2020?) highlighted that many researchers now prefer to use automated ML-OBIA methods within the remote sensing archaeology field, exactly because it helps remove human conscious or unconscious biases, where confounding assumptions could be applied. Although automated analysis could still have their limitations and assumptions, these biases are often explicit and reproducible. But again, all machine learning and automated techniques are built from the initial knowledge base/rule of thumb, so I’m still quite skeptical. Is human bias avoidable at all?\n\n\n\n\nFallatah, Ahmad, Simon Jones, and David Mitchell. 2020. “Object-Based Random Forest Classification for Informal Settlements Identification in the Middle East: Jeddah a Case Study.” International Journal of Remote Sensing 41 (11): 4421–45. https://doi.org/10.1080/01431161.2020.1718237.\n\n\nGhorbanzadeh, Omid, Hejar Shahabi, Alessandro Crivellari, Saeid Homayouni, Thomas Blaschke, and Pedram Ghamisi. 2022. “Landslide Detection Using Deep Learning and Object-Based Image Analysis.” Landslides 19 (4): 929–39. https://doi.org/10.1007/s10346-021-01843-x.\n\n\nGISGeography. 2014. “Image Classification Techniques in Remote Sensing.” https://gisgeography.com/image-classification-techniques-remote-sensing/."
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Urban Heat Island",
    "section": "",
    "text": "This week we look into the Urban Heat Island Effect, policies to combat it across the world how we can use remote sensing techniques to predict, prevent and protect."
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "8  Urban Heat Island",
    "section": "8.1 Application",
    "text": "8.1 Application\n\n8.1.1 The General Situation, What is it?\nThe impacts of the Urban Heat Island (UHI) effect have been difficult to ignore in recent years. Alongside rising global temperatures, higher temperatures experienced in urban areas pose a serious risk toward the health and wellbeing of urban populations. In the UK, the five-day heat wave in July 2022 was associated with 2,800 deaths in over-65s across the country as temperatures rose as high as 40C in central London (“Record Excess Deaths in UK’s Heatwave Summer” (2022) ) .\n\n\n\n\n\n(UrbanHeatIsland?)\n\n\n\n\n\nThere are various factors that contributes to UHI:\n\nHigh density buildings in the urban core that replaced natural covers such as trees and natural water feature drastically reduce cities’ capacity to increase their albedo.\nDark impermeable surfaces such as tarmac roads and black roofs contributes to overheating as dark colours only absorb the heat, instead of reflecting it elsewhere.\nFeedback Loop: the hotter it gets, the more energy cities will use to cool itself down. This means frequent uses of air conditioners which, in the process of generating cool air, is actively pumping out hot air onto the streets.\n\n\nWant more detail? Well well well, you’re in luck:\nClick here!\nIf you’re not seeing anything there at the moment, check back later. It’s worth it – trust me."
  },
  {
    "objectID": "week8.html#what-are-the-impacts",
    "href": "week8.html#what-are-the-impacts",
    "title": "8  Urban Heat Island",
    "section": "8.2 What are the impacts?",
    "text": "8.2 What are the impacts?\n\n8.2.1 Economic\nEstrada, Botzen, and Tol (2017) estimated the % lost from UHI in each GHG level scenario. The lowest GHG scenario still predicts 0.71% to be lost in 2050\n\n\n8.2.2 Environmental\nMentioned briefly above, the hotter it is, the more energy requires to keep people cool. Santamouris et al. (2015) found that each degree of ambient temperature rise increases the peak electricity load around 0.45 and 4.6%. Also taking into account that many countries rely on oil and gas suppliers to supply energy. And from what we experienced (and experiencing) with the geopolitics with Russia, this is bad news for the environment and the wallet.\n\n\n8.2.3 Social: The already disadvantaged gets it the worst\nHarlan et al. (2013) conducted a comprehensive study identifying social and environmental predictors of heat vulnerability in Arizona. The study found deprived areas, especially those with majority black populations and areas of spatial deprivation , where dwellings are considered overcrowded, are particularly vulnerable to heat-related deaths.\nOften, it is exactly these poor urban areas that have the least access to green and blue covers and further away from hospitals for medical assistance Prosdocimi and Klima (2020) found that risk of death is increased by 1.02% per km of distance. Hello redlining!"
  },
  {
    "objectID": "week8.html#global-policies",
    "href": "week8.html#global-policies",
    "title": "8  Urban Heat Island",
    "section": "8.3 Global Policies",
    "text": "8.3 Global Policies\nGlobal policies like the New Urban Agenda, Sustainable Development Goals, COP26 (which is now funded by oil tycoons!) all have general references to the UHI problem, however these global framework are often vague. Which in a way is fair enough because it needs to be applicable for all nations across economic strengths and different infrastructures. These documents are also often extremely long, so not very user friendly either. But this means the responsibility falls onto nation states and city level governments."
  },
  {
    "objectID": "week8.html#local-policies",
    "href": "week8.html#local-policies",
    "title": "8  Urban Heat Island",
    "section": "8.4 Local Policies",
    "text": "8.4 Local Policies\n\n\n\n\n\n\n\n\nPlace\nStrategy\nOutcomes\n\n\n\n\nBarcelona\nSuperblock\nIncreased footfall and consumption, less pollutants, less cars, a lively walkable neigbourhood\n\n\nMedellin\nGreen Corridors\ntransformed undefined spaces that encouraged anti-social behaviours into welcoming spaces, increase quality of life, general cooling effect– but not near where people live…\n\n\nSydney Western Suburbs\nTurn Down the Heat Strategy\nThe first real guide from a city level that highlights the need to address UHI.\nBut provided no specifics. Yes we need to mitigate and prevent, but where? how? how much? who?\n\n\nBaltimore\ntree vouchers\nThis pushes the responsibilities towards city dwellers, when in fact large scale top down policies needs to be enforced by the government\n\n\nFremantle\nUrban forest Plan\nyay for data driven policy! But they only used 1 month’s data. Really should be using aggregate.\n\n\nPerth Met Area\n1955 requirement for 10% of open space\nOpen space != green space…\n\n\n\nWhen thinking about policy, we need to consider what the effect are. Are we aiming for equity, equality or justice? Are we talking about giving everyone equal access to cool areas, or are we actively lifting those who are already disadvantaged?"
  },
  {
    "objectID": "week8.html#application-1",
    "href": "week8.html#application-1",
    "title": "8  Urban Heat Island",
    "section": "8.5 Application",
    "text": "8.5 Application\nLi et al. (2022) wrote a paper that pretty much summarises this week content, exploring the intersection between UHI, policy and injustice. Li measured the effects of UHI using admission to A&E due to heat related emergencies and its relations to historical redlining in Texas.\nLand Surface Data: Taken from ECO2LSTE product, ranging from June to August 2018-2020. This data is to capture heat exposure in different areas. Daytime and nighttime LST are both captured.\nSocial Vulnerability Factors: Taken from American Community Survey 2015-2019. Elderly, non-white population, low income population, population who do not speak English well, population who live alone. These are used as control variables to make sure the analysis is measuring the relationship between redlining areas and LST.\nHeat-related Emergency Department Visits: Provided by Texas Health Centre for statistics between 2016-2019.\nHistorical Redlining: Geo-rectified data from the Mapping Ineqaulity project. The spatial boundaries of the redlined zones are recalculated to ensure the zones fit the zip code tabulation area, based on 50% percentile. Resulting in 2 categories of more redline and less redline.\nMethodology\nOLS regression models were fitted to predict daytime and nighttime LST based on whether or not there are more or less redlining, and the spatial autocorrelation residual is examined.\nOutput\nThe Moran’s I and Spatial Lag model were both statistically significant, suggesting that the variance in LST can be explained by proportion of redlining, with coefficient of 0.0122 for daytime LST, and 0.0098 for nighttime LST.\nThe same analysis was done for LST and A&E heat related admission, and again a significant relationship is found.\nIn my opinion, however, I don’t think LST is representative of the temperature people may experience inside redlined housing. Indeed, amount of tree cover, often lacking in redlined areas can influence LST. However it is often the quality of the building, whether it is well insulated, whether it is equipped with cooling infrastructure is more of a direct measure. Further, the heat related A&E admission could very much be under represented as often those with lower economic status cannot afford a trip to the A&E.\nBut this study goes to show the long lasting effect of policies and how it continues to influence and maintain the structural inequalities in society. It is important to recognise that one size fit all solutions do not tend to create a just society. Instead, policy makers need to be aware of the place-based health disparities arising from historical and structural segregation and racist policies.\nDay & Night UHI\n\n\n\n\n\n\n\n\nAn interesting aspect of UHI I’ve had interest in exploring is the UHI difference during the day and night. There have been debates on whether the UHI Effect is more prominent during the night as there is greater thermal inertial, and heat accumulated throughout the day would radiate Arellano and Roca (2021).\nThe map above is based on the simplified dataset created by Chakraborty and Lee (2019) using SUE algorithm. From MODIS (Moderate Resolution Imaging Spectroradiometer) images, 15 years of Land Surface Temperature data is used to calculated UHI intensity for 9500 urban clusters. Chakraborty et al. calculated both the daytime and nighttime surface UHI for their urban clusters. They found the global mean surface for daytime is 0.85C with 44% showing values greater than 1C. With nighttime, the average UHI intensity is 0.55C, with only 13% showing value greater than 1C. This is because daytime UHI is influenced by more factors (evapourative cooling, surface roughness between urban/rural, anthropocentric heat flux, thermal inertia in buildings ), whereas nighttime UHI is mainly influenced by thermal inertia and anthropocentric heat flux only!"
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "8  Urban Heat Island",
    "section": "8.6 Reflection",
    "text": "8.6 Reflection\nThe Urban Heat Island Effect will only become a more serious concern as time goes on. Especially in the UK, where housing stock is one of the most poorly insulated in Europe – national and city level government need to implement measures that could alleviate effects of extreme heat in the short term (paint roofs white and tree vouchers are only short term solutions, if solutions at all!), but also suggest urban policies to build sustainable green infrastructure and retrofitting homes for higher energy efficiency. Of course, limited funding is a consistent problem within government bodies (apart from funding wars, lockdown parties, building detention centres in Rwanda etc etc ). This is why it is important to utilise data available to use to prioritised communities who are worst affected and address the fundamental problem of injustice, instead of applying a blanket solutions that only perpetuate existing inequality.\n\n\n\n\nArellano, B., and J. Roca. 2021. “REMOTE SENSING AND NIGHT TIME URBAN HEAT ISLAND.” The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences XLIII-B3-2021 (June): 15–22. https://doi.org/10.5194/isprs-archives-XLIII-B3-2021-15-2021.\n\n\nChakraborty, T., and X. Lee. 2019. “A Simplified Urban-Extent Algorithm to Characterize Surface Urban Heat Islands on a Global Scale and Examine Vegetation Control on Their Spatiotemporal Variability.” International Journal of Applied Earth Observation and Geoinformation 74 (February): 269–80. https://doi.org/10.1016/j.jag.2018.09.015.\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017. “A Global Economic Assessment of City Policies to Reduce Climate Change Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nHarlan, Sharon L., -Barreto Juan H. Declet, William L. Stefanov, and Diana B. Petitti. 2013. “Neighborhood Effects on Heat Deaths: Social and Environmental Predictors of Vulnerability in Maricopa County, Arizona.” Environmental Health Perspectives 121 (2): 197–204. https://doi.org/10.1289/ehp.1104625.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown. 2022. “Modeling the Relationships Between Historical Redlining, Urban Heat, and Heat-Related Emergency Department Visits: An Examination of 11 Texas Cities.” Environment and Planning B: Urban Analytics and City Science 49 (3): 933–52. https://doi.org/10.1177/23998083211039854.\n\n\nProsdocimi, Diogo, and Kelly Klima. 2020. “Health Effects of Heat Vulnerability in Rio de Janeiro: A Validation Model for Policy Applications.” SN Applied Sciences 2 (12): 1948. https://doi.org/10.1007/s42452-020-03750-7.\n\n\n“Record Excess Deaths in UK’s Heatwave Summer.” 2022. BBC News, October. https://www.bbc.com/news/health-63171417.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015. “On the Impact of Urban Heat Island and Global Warming on the Power Demand and Electricity Consumption of BuildingsA Review.” Energy and Buildings, Renewable Energy Sources and Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arellano, B., and J. Roca. 2021. “REMOTE SENSING AND NIGHT TIME\nURBAN HEAT ISLAND.” The International Archives of the\nPhotogrammetry, Remote Sensing and Spatial Information Sciences\nXLIII-B3-2021 (June): 15–22. https://doi.org/10.5194/isprs-archives-XLIII-B3-2021-15-2021.\n\n\nAssarkhaniki, Zahra, Soheil Sabri, and Abbas Rajabifard. 2021.\n“Using Open Data to Detect the Structure and Pattern of Informal\nSettlements: An Outset to Support Inclusive SDGs’\nAchievement.” Big Earth Data 5 (4): 497–526. https://doi.org/10.1080/20964471.2021.1948178.\n\n\nBadmos, Olabisi S., Andreas Rienow, Daniel Callo-Concha, Klaus Greve,\nand Carsten Jürgens. 2018. “Urban Development in West\nAfricaMonitoring and Intensity Analysis of Slum Growth in\nLagos: Linking Pattern and Process.” Remote Sensing 10\n(7): 1044. https://doi.org/10.3390/rs10071044.\n\n\nChakraborty, T., and X. Lee. 2019. “A Simplified Urban-Extent\nAlgorithm to Characterize Surface Urban Heat Islands on a Global Scale\nand Examine Vegetation Control on Their Spatiotemporal\nVariability.” International Journal of Applied Earth\nObservation and Geoinformation 74 (February): 269–80. https://doi.org/10.1016/j.jag.2018.09.015.\n\n\nCook, Kerry H., Rory G. J. Fitzpatrick, Weiran Liu, and Edward K. Vizy.\n2020. “Seasonal Asymmetry of Equatorial East African Rainfall\nProjections: Understanding Differences Between the Response of the Long\nRains and the Short Rains to Increased Greenhouse Gases.”\nClimate Dynamics 55 (7): 1759–77. https://doi.org/10.1007/s00382-020-05350-y.\n\n\nDe Risi, R., F. Jalayer, F. De Paola, I. Iervolino, M. Giugni, M. E.\nTopa, E. Mbuya, A. Kyessi, G. Manfredi, and P. Gasparini. 2013.\n“Flood Risk Assessment for Informal Settlements.”\nNatural Hazards 69 (1): 1003–32. https://doi.org/10.1007/s11069-013-0749-0.\n\n\nDuque, Juan C., Jorge E. Patino, Luis A. Ruiz, and Josep E.\nPardo-Pascual. 2015. “Measuring Intra-Urban Poverty Using Land\nCover and Texture Metrics Derived from Remote Sensing Data.”\nLandscape and Urban Planning 135 (March): 11–21. https://doi.org/10.1016/j.landurbplan.2014.11.009.\n\n\n“Economic Growth and Trade | Kenya.” 2023. https://www.usaid.gov/kenya/economic-growth-and-trade.\n\n\nElkhrachy, Ismail. 2022. “Flash Flood Water Depth Estimation\nUsing SAR Images, Digital Elevation Models, and\nMachine Learning Algorithms.” Remote\nSensing 14 (3): 440. https://doi.org/10.3390/rs14030440.\n\n\n“ESA and Climate.” n.d.\nhttps://www.esa.int/Applications/Observing_the_Earth/Space_for_our_climate/ESA_and_climate.\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017.\n“A Global Economic Assessment of City Policies to Reduce Climate\nChange Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nFallatah, Ahmad, Simon Jones, and David Mitchell. 2020.\n“Object-Based Random Forest Classification for Informal\nSettlements Identification in the Middle East: Jeddah a Case\nStudy.” International Journal of Remote Sensing 41 (11):\n4421–45. https://doi.org/10.1080/01431161.2020.1718237.\n\n\nGavier-Pizarro, Gregorio I., Tobias Kuemmerle, Laura E. Hoyos, Susan I.\nStewart, Cynthia D. Huebner, Nicholas S. Keuler, and Volker C. Radeloff.\n2012. “Monitoring the Invasion of an Exotic Tree (Ligustrum\nLucidum) from 1983 to 2006 with Landsat TM/ETM+ Satellite Data and\nSupport Vector Machines in Córdoba, Argentina.” Remote\nSensing of Environment, Landsat Legacy Special Issue, 122 (July):\n134–45. https://doi.org/10.1016/j.rse.2011.09.023.\n\n\nGhorbanzadeh, Omid, Hejar Shahabi, Alessandro Crivellari, Saeid\nHomayouni, Thomas Blaschke, and Pedram Ghamisi. 2022. “Landslide\nDetection Using Deep Learning and Object-Based Image Analysis.”\nLandslides 19 (4): 929–39. https://doi.org/10.1007/s10346-021-01843-x.\n\n\nGISGeography. 2014. “Image Classification Techniques in Remote\nSensing.” https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\n———. 2017. “Why the Atmospheric Window Matters in Earth\nScience.” https://gisgeography.com/atmospheric-window/.\n\n\nGlobal Partnership for Result-Based Appraoaches. n.d. “Kenya:\nAssessment of Kayole-Soweto Informal Settlement | the Global Partnership\nfor Results-Based Approaches (GPRBA).” https://www.gprba.org/activities/kayole-soweto-informal-settlement.\n\n\nGreen, Norman. 1957. “Aerial Photographic\nInterpretation and the Social Structure of the\nCity.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nHarlan, Sharon L., -Barreto Juan H. Declet, William L. Stefanov, and\nDiana B. Petitti. 2013. “Neighborhood Effects on Heat Deaths:\nSocial and Environmental Predictors of Vulnerability in Maricopa County,\nArizona.” Environmental Health Perspectives 121 (2):\n197–204. https://doi.org/10.1289/ehp.1104625.\n\n\nJensen, J. R. 1986. “Introductory Digital Image Processing: A\nRemote Sensing Perspective.” https://www.osti.gov/biblio/5166368.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown.\n2022. “Modeling the Relationships Between Historical Redlining,\nUrban Heat, and Heat-Related Emergency Department Visits: An Examination\nof 11 Texas Cities.” Environment and Planning B: Urban\nAnalytics and City Science 49 (3): 933–52. https://doi.org/10.1177/23998083211039854.\n\n\nLi, G., and Q. Weng. 2007. “Measuring the Quality of Life in City\nof Indianapolis by Integration of Remote Sensing and Census\nData.” International Journal of Remote Sensing 28 (2):\n249–67. https://doi.org/10.1080/01431160600735624.\n\n\nMatricardi, Eraldo A. T., David L. Skole, Marcos A. Pedlowski, Walter\nChomentowski, and Luis Claudio Fernandes. 2010. “Assessment of\nTropical Forest Degradation by Selective Logging and Fire Using\nLandsat Imagery.” Remote Sensing of\nEnvironment 114 (5): 1117–29. https://doi.org/10.1016/j.rse.2010.01.001.\n\n\nMulligan, Joe, Jamilla Harper, Pascal Kipkemboi, Bukonola Ngobi, and\nAnna Collins. 2017. “Community-Responsive Adaptation to Flooding\nin Kibera, Kenya.” Proceedings of the Institution of Civil\nEngineers - Engineering Sustainability 170 (5): 268–80. https://doi.org/10.1680/jensu.15.00060.\n\n\n“Nairobi.” n.d. https://www.c40.org/cities/nairobi/.\n\n\n“Nairobi Climate Action Plan 2020-2050 Summary Booklet | Nairobi\nCity County.” 2022. https://nairobi.go.ke/climate-action-plan-2020-2050/.\n\n\nOtukei, J. R., and T. Blaschke. 2010. “Land Cover Change\nAssessment Using Decision Trees, Support Vector Machines and Maximum\nLikelihood Classification Algorithms.” International Journal\nof Applied Earth Observation and Geoinformation, Supplement Issue\non \"Remote Sensing for Africa  A Special\nCollection from the African Association for Remote Sensing of the\nEnvironment (AARSE)\", 12 (February): S27–31. https://doi.org/10.1016/j.jag.2009.11.002.\n\n\nOwusu, Maxwell, Monika Kuffer, Mariana Belgiu, Tais Grippa, Moritz\nLennert, Stefanos Georganos, and Sabine Vanhuysse. 2021. “2021\nIEEE International Geoscience and Remote Sensing Symposium\nIGARSS.” In, 5700–5703. https://doi.org/10.1109/IGARSS47720.2021.9553570.\n\n\nPandey, Prem Chandra, Nicholas J. Tate, and Heiko Balzter. 2014.\n“Mapping Tree Species in Coastal Portugal Using\nStatistically Segmented Principal Component Analysis and\nOther Methods.” IEEE Sensors Journal 14\n(12): 4434–41. https://doi.org/10.1109/JSEN.2014.2335612.\n\n\nPatino, Jorge E., and Juan C. Duque. 2013. “A Review of Regional\nScience Applications of Satellite Remote Sensing in Urban\nSettings.” Computers, Environment and Urban Systems 37\n(January): 1–17. https://doi.org/10.1016/j.compenvurbsys.2012.06.003.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002.\n“Monitoring the Composition of Urban Environments Based on the\nVegetation-Impervious Surface-Soil (VIS) Model by Subpixel\nAnalysis Techniques.” International Journal of Remote\nSensing 23 (20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\nProsdocimi, Diogo, and Kelly Klima. 2020. “Health Effects of Heat\nVulnerability in Rio de Janeiro: A Validation Model for Policy\nApplications.” SN Applied Sciences 2 (12): 1948. https://doi.org/10.1007/s42452-020-03750-7.\n\n\n“Record Excess Deaths in UK’s Heatwave Summer.” 2022.\nBBC News, October. https://www.bbc.com/news/health-63171417.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015.\n“On the Impact of Urban Heat Island and Global Warming on the\nPower Demand and Electricity Consumption of BuildingsA\nReview.” Energy and Buildings, Renewable Energy Sources\nand Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052.\n\n\n“Site Suitability Evaluation for Urban\nDevelopment Using Remote Sensing, GIS and\nAnalytic Hierarchy Process (AHP) |\nSpringerLink.” n.d.\nhttps://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\n“Site Suitability Evaluation for Urban Development Using Remote\nSensing, GIS and Analytic Hierarchy Process (AHP) |\nSpringerLink.” n.d. https://link.springer.com/chapter/10.1007/978-981-10-2107-7_34.\n\n\nSriwongsitanon, Nutchanart, Kritsanat Surakit, and Sansarith\nThianpopirug. 2011. “Influence of Atmospheric Correction and\nNumber of Sampling Points on the Accuracy of Water Clarity Assessment\nUsing Remote Sensing Application.” Journal of Hydrology\n401 (3): 203–20. https://doi.org/10.1016/j.jhydrol.2011.02.023.\n\n\nSultana, Sabiha, and A. N. V. Satyanarayana. 2020. “Assessment of\nUrbanisation and Urban Heat Island Intensities Using Landsat Imageries\nDuring 2000 2018 over a Sub-Tropical Indian City.”\nSustainable Cities and Society 52 (January): 101846. https://doi.org/10.1016/j.scs.2019.101846.\n\n\nSutton, Paul C. 2003. “A Scale-Adjusted Measure of\n‘Urban Sprawl’ Using Nighttime Satellite\nImagery.” Remote Sensing of Environment, Urban\nRemote Sensing, 86 (3): 353–69. https://doi.org/10.1016/S0034-4257(03)00078-6.\n\n\nTeam, Investigative Tech. 2020. “The Disappearance of Quitobaquito\nSprings: Tracking Hydrologic Change with Google Earth Engine.” https://www.bellingcat.com/resources/2020/10/01/the-disappearance-of-quitobaquito-springs-tracking-hydrologic-change-with-google-earth-engine/.\n\n\nUN Habitat. n.d. “Kenya: Nairobi Urban Profile |\nUN-Habitat.” https://unhabitat.org/kenya-nairobi-urban-profile.\n\n\nWang, Jianghao, Yong Ge, Gerard B. M. Heuvelink, Chenghu Zhou, and Dick\nBrus. 2012. “Effect of the Sampling Design of Ground Control\nPoints on the Geometric Correction of Remotely Sensed Imagery.”\nInternational Journal of Applied Earth Observation and\nGeoinformation 18 (August): 91–100. https://doi.org/10.1016/j.jag.2012.01.001.\n\n\nWEBER, C., and J. HIRSCH. 1992. “Some Urban Measurements from\nSPOT Data: Urban Life Quality Indices.”\nInternational Journal of Remote Sensing 13 (17): 3251–61. https://doi.org/10.1080/01431169208904116.\n\n\n“What Is Orthorectified Imagery?” n.d. https://www.esri.com/about/newsroom/insider/what-is-orthorectified-imagery/."
  }
]